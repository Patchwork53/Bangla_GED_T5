{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afa28ebf",
   "metadata": {
    "papermill": {
     "duration": 0.012553,
     "end_time": "2023-03-10T09:13:44.592140",
     "exception": false,
     "start_time": "2023-03-10T09:13:44.579587",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference Notebook\n",
    "Model: /kaggle/input/schadenfreude-bhashabhrom/banglat5 <br>\n",
    "Model Source: Finetuned https://huggingface.co/csebuetnlp/banglat5_small for 120 epochs on DataSetFold1.csv (see training notebook ) <br>\n",
    "\n",
    "Dataset : DataSetFold1_u.csv, DataSetFold2.csv, test.csv <br>\n",
    "\n",
    "### Input\n",
    "* /kaggle/input/bangla-ged : Contains the datasets provided by the hosts of EEEDay Datathon\n",
    "* /kaggle/input/bangla-sadhu-verbs/sadhu.txt : Contains about 300 Bangla Verbs (Produced by me using Github Copilot)\n",
    "* /kaggle/input/schadenfreude-bhashabhrom/banglat5 : Finetuned banglat5_small from the notebook Schadenfreude_EEEDay_Training\n",
    "\n",
    "### Output\n",
    "This notebook outputs:\n",
    "* submission.csv\n",
    "* Miscellaneous intermediate files\n",
    "\n",
    "\n",
    "### Credit\n",
    "Dataset provided by the Hosts of EEEDAY 2023 Datathon\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c0977cd",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-03-10T09:13:44.613100Z",
     "iopub.status.busy": "2023-03-10T09:13:44.612595Z",
     "iopub.status.idle": "2023-03-10T09:14:39.503985Z",
     "shell.execute_reply": "2023-03-10T09:14:39.502808Z"
    },
    "papermill": {
     "duration": 54.904719,
     "end_time": "2023-03-10T09:14:39.506623",
     "exception": false,
     "start_time": "2023-03-10T09:13:44.601904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q datasets\n",
    "!pip install -q git+https://github.com/csebuetnlp/normalizer\n",
    "!pip install -q transformers\n",
    "!pip install -q levenshtein\n",
    "!pip install -q gdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf60501",
   "metadata": {
    "papermill": {
     "duration": 0.010075,
     "end_time": "2023-03-10T09:14:39.527311",
     "exception": false,
     "start_time": "2023-03-10T09:14:39.517236",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Changing the Test File (/Prediction File)\n",
    "\n",
    "By default the test file is /kaggle/input/bangla-ged/test.csv <br>\n",
    "To replace it, change the following code block <br>\n",
    "The format has to match the original test.csv <br>\n",
    "For some post-processing, the test.csv is read directly (not with pandas). Due to Windows using \\r\\n and Linux using \\n, there might be some problem if the test.csv was made in Windows, although I think I've handled it <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cae23238",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-10T09:14:39.550740Z",
     "iopub.status.busy": "2023-03-10T09:14:39.549089Z",
     "iopub.status.idle": "2023-03-10T09:14:39.554656Z",
     "shell.execute_reply": "2023-03-10T09:14:39.553776Z"
    },
    "papermill": {
     "duration": 0.019091,
     "end_time": "2023-03-10T09:14:39.556659",
     "exception": false,
     "start_time": "2023-03-10T09:14:39.537568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_file_or_path = \"/kaggle/input/bangla-ged/test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee9619e",
   "metadata": {
    "papermill": {
     "duration": 0.010268,
     "end_time": "2023-03-10T09:14:39.577129",
     "exception": false,
     "start_time": "2023-03-10T09:14:39.566861",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Example of how to change the test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12c05ef4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-10T09:14:39.599282Z",
     "iopub.status.busy": "2023-03-10T09:14:39.598392Z",
     "iopub.status.idle": "2023-03-10T09:14:39.603079Z",
     "shell.execute_reply": "2023-03-10T09:14:39.602288Z"
    },
    "papermill": {
     "duration": 0.017739,
     "end_time": "2023-03-10T09:14:39.604980",
     "exception": false,
     "start_time": "2023-03-10T09:14:39.587241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import gdown\n",
    "# # url = \"https://drive.google.com/uc?id=1iXsDI8yFTnJ27k80iPSBJ4YsjJVcOmgD\"\n",
    "\n",
    "# url = \"https://drive.google.com/uc?id=10WrOwETFFsU4-0xiwtm7tGgWUDWCZ-aP\"\n",
    "# output = \"/kaggle/working/test.csv\"\n",
    "# gdown.download(url,output, quiet=False)\n",
    "# test_file_or_path = \"/kaggle/working/test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ecd7d1",
   "metadata": {
    "papermill": {
     "duration": 0.010019,
     "end_time": "2023-03-10T09:14:39.625138",
     "exception": false,
     "start_time": "2023-03-10T09:14:39.615119",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Creating files for Preprocessing and Postprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84d75dd",
   "metadata": {
    "papermill": {
     "duration": 0.009912,
     "end_time": "2023-03-10T09:14:39.645174",
     "exception": false,
     "start_time": "2023-03-10T09:14:39.635262",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Making train.json, test.json and validation.json in kaggle/working/mt5_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0324dfbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-10T09:14:39.667164Z",
     "iopub.status.busy": "2023-03-10T09:14:39.666469Z",
     "iopub.status.idle": "2023-03-10T09:14:41.552059Z",
     "shell.execute_reply": "2023-03-10T09:14:41.550906Z"
    },
    "papermill": {
     "duration": 1.899178,
     "end_time": "2023-03-10T09:14:41.554498",
     "exception": false,
     "start_time": "2023-03-10T09:14:39.655320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "rm: cannot remove '/kaggle/working/mt5_input': No such file or directory\r\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!rm -r /kaggle/working/mt5_input\n",
    "!mkdir /kaggle/working/mt5_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d31afcd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-10T09:14:41.577647Z",
     "iopub.status.busy": "2023-03-10T09:14:41.576806Z",
     "iopub.status.idle": "2023-03-10T09:14:42.476216Z",
     "shell.execute_reply": "2023-03-10T09:14:42.475256Z"
    },
    "papermill": {
     "duration": 0.913567,
     "end_time": "2023-03-10T09:14:42.478788",
     "exception": false,
     "start_time": "2023-03-10T09:14:41.565221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import codecs\n",
    "import sys\n",
    "import re\n",
    "\n",
    "\n",
    "# DataSetFold1_u.csv has a single sentence with a newline inside it. \n",
    "# The JSONL input required by the model can not handle sentences with embedded new lines\n",
    "# Must omit the newline pseudo-manually\n",
    "train_file_or_path = \"/kaggle/input/bangla-ged/DataSetFold1_u.csv\"\n",
    "\n",
    "newline_removed = \"\"\n",
    "with codecs.open(train_file_or_path,encoding = 'utf8', mode=\"r\") as f:\n",
    "    whole_content = f.read()\n",
    "    newline_removed = re.sub(r\"কপোল\\n\", r\"কপোল\", whole_content)\n",
    "    newline_removed = re.sub(r\"\\$কপোল\\$\\n\", r\"$কপোল$\", newline_removed)\n",
    "\n",
    "train_file_or_path = \"/kaggle/working/DataSetFold1_u.csv\"\n",
    "with codecs.open(train_file_or_path,encoding = 'utf8', mode=\"w\") as f:\n",
    "    f.write(newline_removed)\n",
    "\n",
    "\n",
    "#making train.json\n",
    "\n",
    "\n",
    "df = pd.read_csv(train_file_or_path, encoding = 'utf8')\n",
    "\n",
    "with codecs.open(\"/kaggle/working/mt5_input/train.json\", encoding = 'utf8', mode='w') as f:\n",
    "    for idx, row in df.iterrows():\n",
    "        sentence = row[\"sentence\"]\n",
    "        gt = row[\"gt\"]\n",
    "        sentence = sentence.replace(\"\\\"\", \"\\\\\\\"\")\n",
    "        gt = gt.replace(\"\\\"\", \"\\\\\\\"\")\n",
    "        f.write(\"{\\\"source\\\": \\\"\" + sentence + \"\\\", \\\"target\\\": \\\"\" + gt + \"\\\"}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "#making test.json\n",
    "\n",
    "df = pd.read_csv(test_file_or_path, encoding = 'utf8')\n",
    "with codecs.open(\"/kaggle/working/mt5_input/test.json\", encoding = 'utf8', mode='w') as f:\n",
    "    for idx, row in df.iterrows():\n",
    "        sentence = row[\"text\"]\n",
    "        sentence = sentence.replace(\"\\\"\", \"\\\\\\\"\")\n",
    "        gt = \"\"\n",
    "        # gt = row[\"gt\"]\n",
    "        # gt = gt.replace(\"\\\"\", \"\\\\\\\"\")\n",
    "        f.write(\"{\\\"source\\\": \\\"\" + sentence + \"\\\", \\\"target\\\": \\\"\" + gt + \"\\\"}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "017efdd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-10T09:14:42.501327Z",
     "iopub.status.busy": "2023-03-10T09:14:42.501002Z",
     "iopub.status.idle": "2023-03-10T09:14:43.603448Z",
     "shell.execute_reply": "2023-03-10T09:14:43.602326Z"
    },
    "papermill": {
     "duration": 1.116245,
     "end_time": "2023-03-10T09:14:43.605743",
     "exception": false,
     "start_time": "2023-03-10T09:14:42.489498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n"
     ]
    }
   ],
   "source": [
    "!tail -n 1000 /kaggle/working/mt5_input/train.json > /kaggle/working/mt5_input/validation.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "643550ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-10T09:14:43.628720Z",
     "iopub.status.busy": "2023-03-10T09:14:43.628359Z",
     "iopub.status.idle": "2023-03-10T09:14:44.569464Z",
     "shell.execute_reply": "2023-03-10T09:14:44.568385Z"
    },
    "papermill": {
     "duration": 0.955299,
     "end_time": "2023-03-10T09:14:44.571739",
     "exception": false,
     "start_time": "2023-03-10T09:14:43.616440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "test.json  train.json  validation.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls /kaggle/working/mt5_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10725794",
   "metadata": {
    "papermill": {
     "duration": 0.011257,
     "end_time": "2023-03-10T09:14:44.594132",
     "exception": false,
     "start_time": "2023-03-10T09:14:44.582875",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Making files required for postprocessing in kaggle/working/post_process\n",
    "* test_sentences.txt (test.csv in .txt format without column name)\n",
    "* combined.csv (DataSetFold1_u.csv + DataSetFold2.csv)\n",
    "* error_words.txt (List of words from combined.csv that are commonly flagged as errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ceb493d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-10T09:14:44.616907Z",
     "iopub.status.busy": "2023-03-10T09:14:44.616144Z",
     "iopub.status.idle": "2023-03-10T09:14:46.522449Z",
     "shell.execute_reply": "2023-03-10T09:14:46.521303Z"
    },
    "papermill": {
     "duration": 1.920441,
     "end_time": "2023-03-10T09:14:46.524928",
     "exception": false,
     "start_time": "2023-03-10T09:14:44.604487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "rm: cannot remove '/kaggle/working/post_process': No such file or directory\r\n",
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n"
     ]
    }
   ],
   "source": [
    "!rm -r /kaggle/working/post_process\n",
    "!mkdir /kaggle/working/post_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1465972",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-10T09:14:46.548342Z",
     "iopub.status.busy": "2023-03-10T09:14:46.547688Z",
     "iopub.status.idle": "2023-03-10T09:14:47.489071Z",
     "shell.execute_reply": "2023-03-10T09:14:47.487911Z"
    },
    "papermill": {
     "duration": 0.955359,
     "end_time": "2023-03-10T09:14:47.491411",
     "exception": false,
     "start_time": "2023-03-10T09:14:46.536052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n"
     ]
    }
   ],
   "source": [
    "!tail -n +2 $test_file_or_path > /kaggle/working/post_process/test_sentences.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d341922",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-10T09:14:47.514452Z",
     "iopub.status.busy": "2023-03-10T09:14:47.513798Z",
     "iopub.status.idle": "2023-03-10T09:14:48.456091Z",
     "shell.execute_reply": "2023-03-10T09:14:48.454941Z"
    },
    "papermill": {
     "duration": 0.956354,
     "end_time": "2023-03-10T09:14:48.458559",
     "exception": false,
     "start_time": "2023-03-10T09:14:47.502205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n"
     ]
    }
   ],
   "source": [
    "!cp /kaggle/working/DataSetFold1_u.csv /kaggle/working/post_process/combined.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2202953",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-10T09:14:48.481906Z",
     "iopub.status.busy": "2023-03-10T09:14:48.481503Z",
     "iopub.status.idle": "2023-03-10T09:14:49.478392Z",
     "shell.execute_reply": "2023-03-10T09:14:49.477271Z"
    },
    "papermill": {
     "duration": 1.011101,
     "end_time": "2023-03-10T09:14:49.480635",
     "exception": false,
     "start_time": "2023-03-10T09:14:48.469534",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n"
     ]
    }
   ],
   "source": [
    "!tail -n +2 /kaggle/input/bangla-ged/DataSetFold2.csv >> /kaggle/working/post_process/combined.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a66fb69",
   "metadata": {
    "papermill": {
     "duration": 0.01052,
     "end_time": "2023-03-10T09:14:49.502832",
     "exception": false,
     "start_time": "2023-03-10T09:14:49.492312",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## error_words.txt\n",
    "This file contains a list of (word, occurence_count, error_count, ratio) tuples created from combined.csv\n",
    "This is mainly used to handle sentences which the main t5 model cannot correctly predict. Above a certain ratio (error_count/occurence_count), words are surrounded by \\$ using regex\n",
    "\n",
    "NB: The regex used to create this txt file is a word in progress and fails to find all occurences of words. If the occurence count is zero, the words aren't included in error_words.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc040560",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-10T09:14:49.525967Z",
     "iopub.status.busy": "2023-03-10T09:14:49.525616Z",
     "iopub.status.idle": "2023-03-10T09:15:16.818642Z",
     "shell.execute_reply": "2023-03-10T09:15:16.817065Z"
    },
    "papermill": {
     "duration": 27.308103,
     "end_time": "2023-03-10T09:15:16.821517",
     "exception": false,
     "start_time": "2023-03-10T09:14:49.513414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Regex Error: $মাছ টাই$ 0 1\n",
      "Skipping Regex Error: $□ $ 0 1\n",
      "Skipping Regex Error: $বানাইছে$ 0 1\n",
      "Skipping Regex Error: $বেসসা$ 0 1\n",
      "Skipping Regex Error: $বাংগালী$ 0 1\n",
      "Skipping Regex Error: $ পুলিশের কাঁধে ভর করে যখন সরকার চলে তখন $ 0 1\n",
      "Skipping Regex Error: $ দেশের আইন শৃঙ্খলা $ 0 1\n",
      "Skipping Regex Error: $ স্বাভাবিক $ 0 1\n",
      "Skipping Regex Error: $...।$ 0 2\n",
      "Skipping Regex Error: $মেডাম$ 0 1\n",
      "Skipping Regex Error: $মাইরালা$ 0 1\n",
      "Skipping Regex Error: $দোকান গুলোতে$ 0 1\n",
      "Skipping Regex Error: $ব্লগ  $ 0 1\n",
      "Skipping Regex Error: $সদেগাপ$ 0 1\n",
      "Skipping Regex Error: $,,,,।$ 0 1\n",
      "Skipping Regex Error: $ :-D$ 0 1\n",
      "Skipping Regex Error: $হালারপুয়েরা$ 0 1\n",
      "Skipping Regex Error: $৮) $ 0 1\n",
      "Skipping Regex Error: $ক্যামনে$ 0 1\n",
      "Skipping Regex Error: $*;;;;;;$ 0 1\n",
      "Skipping Regex Error: $তোর বাপ তো $ 0 1\n",
      "Skipping Regex Error: $আজাড়ে$ 0 1\n",
      "Skipping Regex Error: $সোদাও$ 0 1\n",
      "Skipping Regex Error: $জ্ঞান-$ 0 1\n",
      "Skipping Regex Error: $।}$ 0 1\n",
      "Skipping Regex Error: $ভালবা‌সি$ 0 1\n",
      "Skipping Regex Error: $লড়ে$ 0 1\n",
      "Skipping Regex Error: $ ধর্ম ধারণা $ 0 1\n",
      "Skipping Regex Error: $৬. কোন$ 0 1\n",
      "Skipping Regex Error: $হালসাস$ 0 1\n",
      "Skipping Regex Error: $!!!$ 0 1\n",
      "Skipping Regex Error: $।।।।$ 0 1\n",
      "Skipping Regex Error: $কমেনা$ 0 1\n",
      "Skipping Regex Error: $খ. $ 0 1\n",
      "Skipping Regex Error: $চাইছিলো$ 0 1\n",
      "Skipping Regex Error: $ছাএদল$ 0 1\n",
      "Skipping Regex Error: $' $ 0 1\n",
      "Skipping Regex Error: $ভিশ্ব সেরা$ 0 1\n",
      "Skipping Regex Error: $অসাদারন$ 0 1\n",
      "Skipping Regex Error: $পারতোনা$ 0 1\n",
      "Skipping Regex Error: $দিওনা$ 0 1\n",
      "Skipping Regex Error: $প্রাইভেট  $ 0 1\n",
      "Skipping Regex Error: $শেয়ার হোল্ডার , কিংবা ওখানে কাজ করে, সরকারী হাসপাতাল থেকে রোগী $ 0 1\n",
      "Skipping Regex Error: $এক্সপোর্টের  থেকে $ 0 1\n",
      "Skipping Regex Error: $ঘৃনা টা$ 0 1\n",
      "Skipping Regex Error: $বাদাইমা$ 0 1\n",
      "Skipping Regex Error: $...{))।$ 0 1\n",
      "Skipping Regex Error: $আললাহ$ 0 1\n",
      "Skipping Regex Error: $আপ্নারাই$ 0 1\n",
      "Skipping Regex Error: $শেষ-$ 0 1\n",
      "Skipping Regex Error: $..।$ 0 1\n",
      "Skipping Regex Error: $তাঁকে $ 0 1\n",
      "Skipping Regex Error: $স্টেইনলেস  $ 0 1\n",
      "Skipping Regex Error: $ছড়া ছড়ি$ 0 1\n",
      "Skipping Regex Error: $,,,,,,,,,,,,,,,,,,,,,....,$ 0 1\n",
      "Skipping Regex Error: $!।$ 0 1\n",
      "Skipping Regex Error: $সালাগরে$ 0 1\n",
      "Skipping Regex Error: $ক্লন্ত$ 0 1\n",
      "Skipping Regex Error: $ফ্রান্সিসকো তে$ 0 1\n",
      "Skipping Regex Error: $কঠিক$ 0 1\n",
      "Skipping Regex Error: $ভালোমন্দ-$ 0 1\n",
      "Skipping Regex Error: $...?$ 0 1\n",
      "Skipping Regex Error: $ করলে ফাঁসির কাষ্ঠে $ 0 1\n",
      "Skipping Regex Error: $’‘$ 0 4\n",
      "Skipping Regex Error: $(↱)$ 0 1\n",
      "Skipping Regex Error: $ভায় এর$ 0 1\n",
      "Skipping Regex Error: $\"।$ 0 2\n",
      "Skipping Regex Error: $““$ 0 1\n",
      "Skipping Regex Error: $[42]$ 0 1\n",
      "Skipping Regex Error: $এটা $ 0 1\n",
      "Skipping Regex Error: $মিমি -- $ 0 1\n",
      "Skipping Regex Error: $মত $ 0 1\n",
      "Skipping Regex Error: $দরজার $ 0 1\n",
      "Skipping Regex Error: $হল।$ 0 2\n",
      "Skipping Regex Error: $কি।$ 0 1\n",
      "Skipping Regex Error: $’দাদা… ‘$ 0 1\n",
      "Skipping Regex Error: $’নীলা… ‘$ 0 1\n",
      "Skipping Regex Error: $একটি আর $ 0 1\n",
      "Skipping Regex Error: $\"-\"$ 0 1\n",
      "Skipping Regex Error: $নয়পরেরদিন$ 0 1\n",
      "Skipping Regex Error: $– পূর্ণ।$ 0 1\n",
      "Skipping Regex Error: $বলবো।$ 0 1\n",
      "Skipping Regex Error: $'_$ 0 1\n",
      "Skipping Regex Error: $ফাঁক ফোঁকরেও$ 0 1\n",
      "Skipping Regex Error: $শেরে $ 0 1\n",
      "Skipping Regex Error: $___________________বারো____________________ $ 0 1\n",
      "Skipping Regex Error: $আরকি।$ 0 1\n",
      "Skipping Regex Error: $তাহাদে$ 0 1\n",
      "Skipping Regex Error: $(রা)$ 0 1\n",
      "Skipping Regex Error: $ বিমান $ 0 1\n",
      "Skipping Regex Error: $ কয়টি কোন কোন $ 0 1\n",
      "Skipping Regex Error: $'- '$ 0 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import codecs\n",
    "\n",
    "\n",
    "def create_error_words_file(df_path, expected_output_file):\n",
    "    df = pd.read_csv(df_path)\n",
    "\n",
    "    error_words = {}\n",
    "    base_sentences = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        base_line = row['sentence']\n",
    "        base_sentences.append(base_line)\n",
    "        row_data = row['gt']\n",
    "        parts = re.split(\"(\\$[^$]*\\$)\", row_data)\n",
    "         \n",
    "        for part in parts:\n",
    "            if part.startswith(\"$\") and part.endswith(\"$\"):\n",
    "                if len(part) > 3:\n",
    "                    if part in error_words.keys():\n",
    "                        error_words[part] +=1\n",
    "                    else:\n",
    "                        error_words[part] = 1\n",
    "                    # error_words.add(part)\n",
    "\n",
    "    sorted_error_words = []\n",
    "\n",
    "    with codecs.open(expected_output_file, encoding = 'utf8', mode='w') as f:\n",
    "        for item in error_words.keys():\n",
    "            occ_count = 0\n",
    "            for sentence in base_sentences:\n",
    "                if item[1:-1] in sentence:\n",
    "                    occ_count+=len(re.findall(r\"(?<![^\\u0980-\\u09FF])\"+re.escape(item[1:-1]) + r\"(?=[^\\u0980-\\u09FF])\",sentence))\n",
    "                    occ_count+=len(re.findall(r\"(?<=[^\\u0980-\\u09FF])\"+re.escape(item[1:-1]) + r\"(?=[^\\u0980-\\u09FF])\",sentence))\n",
    "            \n",
    "            if occ_count > 0:\n",
    "                sorted_error_words.append((error_words[item]/occ_count, item, occ_count, error_words[item]))\n",
    "            else: \n",
    "                print(\"Skipping Regex Error: \" + item, occ_count, error_words[item])\n",
    "                #found the $word$ in [gt] but couldn't find word in [senetence]\n",
    "        sorted_error_words.sort(reverse=True)\n",
    "\n",
    "        sep = \"-:-:-\"\n",
    "        for item in sorted_error_words:\n",
    "            f.write(item[1] +  sep + str(item[0]) + sep + str(item[2]) + sep + str(item[3]) + \"\\n\")\n",
    "\n",
    "            \n",
    "            \n",
    "def file_level_levenshtein(file1, file2):\n",
    "    with codecs.open(filename=file1,encoding='utf8') as f1:\n",
    "        with codecs.open(filename=file2,encoding='utf8') as f2:\n",
    "            total1 = 0\n",
    "            total2 = 0\n",
    "            count = 0\n",
    "            for line1,line2 in zip(f1,f2):\n",
    "                # total1 += my_levenstein(line1,line2)\n",
    "                total1 += distance(line1,line2)\n",
    "                count += 1\n",
    "                \n",
    "\n",
    "\n",
    "create_error_words_file(\"/kaggle/working/post_process/combined.csv\", \"/kaggle/working/post_process/error_words.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35877e03",
   "metadata": {
    "papermill": {
     "duration": 0.012916,
     "end_time": "2023-03-10T09:15:16.848604",
     "exception": false,
     "start_time": "2023-03-10T09:15:16.835688",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference Using Finetuned banglat5_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11994338",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-10T09:15:16.876854Z",
     "iopub.status.busy": "2023-03-10T09:15:16.876435Z",
     "iopub.status.idle": "2023-03-10T09:15:26.455651Z",
     "shell.execute_reply": "2023-03-10T09:15:26.454473Z"
    },
    "papermill": {
     "duration": 9.596788,
     "end_time": "2023-03-10T09:15:26.458254",
     "exception": false,
     "start_time": "2023-03-10T09:15:16.861466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This section was adapted from https://github.com/csebuetnlp/BanglaNLG/blob/main/seq2seq/run_seq2seq.py\n",
    "    \n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import json\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "from Levenshtein import distance\n",
    "\n",
    "import datasets\n",
    "import numpy as np\n",
    "from datasets import load_dataset, load_metric\n",
    "from datasets.io.json import JsonDatasetReader\n",
    "from datasets.io.csv import CsvDatasetReader\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    HfArgumentParser,\n",
    "    M2M100Tokenizer,\n",
    "    MBart50Tokenizer,\n",
    "    MBart50TokenizerFast,\n",
    "    MBartTokenizer,\n",
    "    MBartTokenizerFast,\n",
    "    MBartForConditionalGeneration,\n",
    "    AlbertTokenizer,\n",
    "    AlbertTokenizerFast,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    default_data_collator,\n",
    "    set_seed,\n",
    ")\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "from transformers.utils import check_min_version\n",
    "from transformers.utils.versions import require_version\n",
    "from normalizer import normalize\n",
    "\n",
    "EXT2CONFIG = {\n",
    "    \"csv\" : (CsvDatasetReader, {}),\n",
    "    \"tsv\" : (CsvDatasetReader, {\"sep\": \"\\t\"}),\n",
    "    \"jsonl\": (JsonDatasetReader, {}),\n",
    "    \"json\": (JsonDatasetReader, {})\n",
    "}\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelArguments:\n",
    "    \n",
    "    model_name_or_path: str = field(\n",
    "        metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}\n",
    "    )\n",
    "    cache_dir: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"Where do you want to store the pretrained models downloaded from huggingface.co\"},\n",
    "    )\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataTrainingArguments:\n",
    "    dataset_dir: Optional[str] = field(\n",
    "        default=None, metadata={\n",
    "            \"help\": \"Path to the directory containing the data files. (.csv / .tsv / .jsonl)\"\n",
    "            \"File datatypes will be identified with their prefix names as follows: \"\n",
    "            \"`train`- Training file(s) e.g. `train.csv`/ `train_part1.csv` etc. \"\n",
    "            \"`validation`- Evaluation file(s) e.g. `validation.csv`/ `validation_part1.csv` etc. \"\n",
    "            \"`test`- Test file(s) e.g. `test.csv`/ `test_part1.csv` etc. \"\n",
    "            \"All files for must have the same extension.\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    dataset_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"The name of the dataset to use (via the datasets library).\"}\n",
    "    )\n",
    "    dataset_config_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"The configuration name of the dataset to use (via the datasets library).\"}\n",
    "    )\n",
    "    \n",
    "    overwrite_cache: bool = field(\n",
    "        default=False, metadata={\"help\": \"Overwrite the cached preprocessed datasets or not.\"}\n",
    "    )\n",
    "    max_train_samples: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"For debugging purposes or quicker training, truncate the number of training examples to this \"\n",
    "            \"value if set.\"\n",
    "        },\n",
    "    )\n",
    "    max_eval_samples: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"For debugging purposes or quicker training, truncate the number of evaluation examples to this \"\n",
    "            \"value if set.\"\n",
    "        },\n",
    "    )\n",
    "    max_predict_samples: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"For debugging purposes or quicker training, truncate the number of prediction examples to this \"\n",
    "            \"value if set.\"\n",
    "        },\n",
    "    )\n",
    "    train_file: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"A csv / tsv / jsonl file containing the training data.\"}\n",
    "    )\n",
    "    validation_file: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"A csv / tsv / jsonl file containing the validation data.\"}\n",
    "    )\n",
    "    test_file: Optional[str] = field(default=None, metadata={\"help\": \"A csv / tsv / jsonl file containing the test data.\"})\n",
    "    do_normalize: Optional[bool] = field(default=False, metadata={\"help\": \"Normalize text before feeding to the model.\"})\n",
    "    unicode_norm: Optional[str] = field(default=\"NFKC\", metadata={\"help\": \"Type of unicode normalization\"})\n",
    "    remove_punct: Optional[bool] = field(\n",
    "        default=False, metadata={\n",
    "            \"help\": \"Remove punctuation during normalization. To replace with custom token / selective replacement you should \"\n",
    "            \"use this repo (https://github.com/abhik1505040/normalizer) before feeding the data to the script.\"\n",
    "    })\n",
    "    remove_emoji: Optional[bool] = field(\n",
    "        default=False, metadata={\n",
    "            \"help\": \"Remove emojis during normalization. To replace with custom token / selective replacement you should \"\n",
    "            \"use this repo (https://github.com/abhik1505040/normalizer) before feeding the data to the script.\"\n",
    "    })\n",
    "    remove_urls: Optional[bool] = field(\n",
    "        default=False, metadata={\n",
    "            \"help\": \"Remove urls during normalization. To replace with custom token / selective replacement you should \"\n",
    "            \"use this repo (https://github.com/abhik1505040/normalizer) before feeding the data to the script.\"\n",
    "    })\n",
    "    source_key: Optional[str] = field(\n",
    "        default=\"source\", metadata={\"help\": \"Key / column name in the input file corresponding to the source data\"}\n",
    "    )\n",
    "    target_key: Optional[str] = field(\n",
    "        default=\"target\", metadata={\"help\": \"Key / column name in the input file corresponding to the target data\"}\n",
    "    )\n",
    "\n",
    "    source_lang: Optional[str] = field(default=None, metadata={\"help\": \"Source language id.\"})\n",
    "    target_lang: Optional[str] = field(default=None, metadata={\"help\": \"Target language id.\"})\n",
    "\n",
    "    preprocessing_num_workers: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"The number of processes to use for the preprocessing.\"},\n",
    "    )\n",
    "    max_source_length: Optional[int] = field(\n",
    "        default=1024,\n",
    "        metadata={\n",
    "            \"help\": \"The maximum total input sequence length after tokenization. Sequences longer \"\n",
    "            \"than this will be truncated, sequences shorter will be padded.\"\n",
    "        },\n",
    "    )\n",
    "    max_target_length: Optional[int] = field(\n",
    "        default=128,\n",
    "        metadata={\n",
    "            \"help\": \"The maximum total sequence length for target text after tokenization. Sequences longer \"\n",
    "            \"than this will be truncated, sequences shorter will be padded.\"\n",
    "        },\n",
    "    )\n",
    "    val_max_target_length: Optional[int] = field(\n",
    "        default=128,\n",
    "        metadata={\n",
    "            \"help\": \"The maximum total sequence length for validation target text after tokenization. Sequences longer \"\n",
    "            \"than this will be truncated, sequences shorter will be padded. Will default to `max_target_length`.\"\n",
    "            \"This argument is also used to override the ``max_length`` param of ``model.generate``, which is used \"\n",
    "            \"during ``evaluate`` and ``predict``.\"\n",
    "        },\n",
    "    )\n",
    "    \n",
    "    num_beams: Optional[int] = field(\n",
    "        default=5,\n",
    "        metadata={\n",
    "            \"help\": \"Number of beams to use for evaluation. This argument will be passed to ``model.generate``, \"\n",
    "            \"which is used during ``evaluate`` and ``predict``.\"\n",
    "        },\n",
    "    )\n",
    "    \n",
    "    source_prefix: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"A prefix to add before every source text.\"}\n",
    "    )\n",
    "    \n",
    "    rouge_lang: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"Target language for rouge\",\n",
    "        }    \n",
    "    )\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.train_file is not None and self.validation_file is not None:\n",
    "            train_extension = self.train_file.split(\".\")[-1]\n",
    "            assert train_extension in [\"csv\", \"jsonl\", \"tsv\", \"json\"], \"`train_file` should be a csv / tsv / jsonl file.\"\n",
    "            validation_extension = self.validation_file.split(\".\")[-1]\n",
    "            assert (\n",
    "                validation_extension == train_extension\n",
    "            ), \"`validation_file` should have the same extension csv / tsv / jsonl as `train_file`.\"\n",
    "\n",
    "\n",
    "def main( model_args, data_args, training_args):\n",
    "   \n",
    " \n",
    "    # Setup logging\n",
    "    logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        handlers=[logging.StreamHandler(sys.stdout)],\n",
    "    )\n",
    "\n",
    "    log_level = training_args.get_process_log_level()\n",
    "    logger.setLevel(log_level)\n",
    "    datasets.utils.logging.set_verbosity(log_level)\n",
    "    transformers.utils.logging.set_verbosity(log_level)\n",
    "    transformers.utils.logging.enable_default_handler()\n",
    "    transformers.utils.logging.enable_explicit_format()\n",
    "\n",
    "    # Log on each process the small summary:\n",
    "    logger.warning(\n",
    "        f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"\n",
    "        + f\"distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"\n",
    "    )\n",
    "    logger.info(f\"Training/evaluation parameters {training_args}\")\n",
    "\n",
    "    set_seed(training_args.seed)\n",
    "    has_ext = lambda path: len(os.path.basename(path).split(\".\")) > 1\n",
    "    get_ext = lambda path: os.path.basename(path).split(\".\")[-1]\n",
    "\n",
    "\n",
    "    if data_args.dataset_name is not None:\n",
    "        # Downloading and loading a dataset from the hub.\n",
    "        raw_datasets = load_dataset(\n",
    "            data_args.dataset_name, data_args.dataset_config_name, cache_dir=model_args.cache_dir\n",
    "        )\n",
    "\n",
    "    elif data_args.dataset_dir is not None:\n",
    "        data_files = {}\n",
    "        all_files = glob.glob(\n",
    "            os.path.join(\n",
    "                data_args.dataset_dir,\n",
    "                \"*\"\n",
    "            )\n",
    "        )\n",
    "        all_exts = [get_ext(k) for k in all_files if has_ext(k)]\n",
    "        if not all_exts:\n",
    "            raise ValueError(\"The `dataset_dir` doesnt have any valid file.\")\n",
    "            \n",
    "        selected_ext = max(set(all_exts), key=all_exts.count)\n",
    "        for search_prefix in [\"train\", \"validation\", \"test\"]:\n",
    "            found_files = glob.glob(\n",
    "                os.path.join(\n",
    "                    data_args.dataset_dir,\n",
    "                    search_prefix + \"*\" + selected_ext\n",
    "                )\n",
    "            )\n",
    "            if not found_files:\n",
    "                continue\n",
    "\n",
    "            data_files[search_prefix] = found_files\n",
    "\n",
    "        dataset_configs = EXT2CONFIG[selected_ext]\n",
    "        raw_datasets = dataset_configs[0](\n",
    "            data_files, \n",
    "            **dataset_configs[1]\n",
    "        ).read()\n",
    "        \n",
    "    else:\n",
    "        data_files = {\n",
    "            \"train\": data_args.train_file, \n",
    "            \"validation\": data_args.validation_file,\n",
    "            \"test\": data_args.test_file\n",
    "        }\n",
    "\n",
    "        data_files = {k: v for k, v in data_files.items() if v is not None}\n",
    "        \n",
    "        if not data_files:\n",
    "            raise ValueError(\"No valid input file found.\")\n",
    "\n",
    "        selected_ext = get_ext(list(data_files.values())[0])\n",
    "\n",
    "        dataset_configs = EXT2CONFIG[selected_ext]\n",
    "        raw_datasets = dataset_configs[0](\n",
    "            data_files, \n",
    "            **dataset_configs[1]\n",
    "        ).read()\n",
    "\n",
    "    config = AutoConfig.from_pretrained(\n",
    "        model_args.model_name_or_path,\n",
    "        cache_dir=model_args.cache_dir,     \n",
    "    )\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_args.model_name_or_path,\n",
    "        cache_dir=model_args.cache_dir,\n",
    "        use_fast=False\n",
    "    )\n",
    "    \n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "        model_args.model_name_or_path,\n",
    "        config=config,\n",
    "        cache_dir=model_args.cache_dir,\n",
    "    )\n",
    "\n",
    "   \n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    if data_args.source_lang is not None and data_args.target_lang is not None:\n",
    "        tokenizer.src_lang = data_args.source_lang\n",
    "        tokenizer.tgt_lang = data_args.target_lang\n",
    "    \n",
    "        if isinstance(tokenizer, (MBartTokenizer, MBartTokenizerFast)):\n",
    "            if isinstance(tokenizer, MBartTokenizer):\n",
    "                model.config.decoder_start_token_id = tokenizer.lang_code_to_id[data_args.target_lang]\n",
    "            else:\n",
    "                model.config.decoder_start_token_id = tokenizer.convert_tokens_to_ids(data_args.target_lang)\n",
    "        elif isinstance(tokenizer, AlbertTokenizer):\n",
    "            model.config.decoder_start_token_id = tokenizer._convert_token_to_id_with_added_voc(tokenizer.tgt_lang)\n",
    "\n",
    "\n",
    "    prefix = data_args.source_prefix if data_args.source_prefix is not None else \"\"\n",
    "\n",
    "    for data_type, ds in raw_datasets.items():\n",
    "        assert data_args.source_key in ds.features, f\"Input files doesnt have the `{data_args.source_key}` key\"\n",
    "        if data_type != \"test\":\n",
    "            assert data_args.target_key in ds.features, f\"Input files doesnt have the `{data_args.target_key}` key\"\n",
    "        \n",
    "        ignored_columns = set(ds.column_names) - set([data_args.source_key, data_args.target_key])\n",
    "        raw_datasets[data_type] = ds.remove_columns(ignored_columns)\n",
    "\n",
    "    max_target_length = data_args.max_target_length\n",
    "    \n",
    "    def preprocess_function(examples):\n",
    "        normalization_kwargs = {\n",
    "            \"unicode_norm\": data_args.unicode_norm,\n",
    "            \"punct_replacement\": \" \" if data_args.remove_punct else None,\n",
    "            \"url_replacement\": \" \" if data_args.remove_urls else None,\n",
    "            \"emoji_replacement\": \" \" if data_args.remove_emoji else None\n",
    "        }\n",
    "        \n",
    "        \n",
    "        inputs = [normalize(ex, **normalization_kwargs) if data_args.do_normalize else ex \n",
    "                    for ex in examples[data_args.source_key]]\n",
    "        inputs = [prefix + inp for inp in inputs]\n",
    "\n",
    "        tokenizer_kwargs = {\n",
    "            \"max_length\": data_args.max_source_length, \n",
    "            \"padding\": False,\n",
    "            \"truncation\": True,\n",
    "            \"return_tensors\": \"np\"\n",
    "        }\n",
    "        \n",
    "   \n",
    "        model_inputs = tokenizer(inputs, **tokenizer_kwargs)\n",
    "\n",
    "   \n",
    "        if data_args.target_key in examples:\n",
    "            targets = [normalize(ex, **normalization_kwargs) if data_args.do_normalize else ex\n",
    "                        for ex in examples[data_args.target_key]]\n",
    "\n",
    "            tokenizer_kwargs.update({\"max_length\": max_target_length})\n",
    "            \n",
    "\n",
    "            with tokenizer.as_target_tokenizer():\n",
    "                labels = tokenizer(targets, **tokenizer_kwargs)\n",
    "\n",
    "                \n",
    "            model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "\n",
    "        return model_inputs\n",
    "\n",
    "    if training_args.do_train:\n",
    "        if \"train\" not in raw_datasets:\n",
    "            raise ValueError(\"--do_train requires a train dataset\")\n",
    "        train_dataset = raw_datasets[\"train\"]\n",
    "        if data_args.max_train_samples is not None:\n",
    "            train_dataset = train_dataset.select(range(data_args.max_train_samples))\n",
    "        \n",
    "        with training_args.main_process_first(desc=\"train dataset map pre-processing\"):\n",
    "            train_dataset = train_dataset.map(\n",
    "                preprocess_function,\n",
    "                batched=True,\n",
    "                batch_size= training_args.train_batch_size,\n",
    "                num_proc=data_args.preprocessing_num_workers,\n",
    "                remove_columns=train_dataset.column_names,\n",
    "                load_from_cache_file=not data_args.overwrite_cache,\n",
    "                desc=\"Running tokenizer on train dataset\",\n",
    "            )\n",
    "\n",
    "    if training_args.do_eval:\n",
    "        max_target_length = data_args.val_max_target_length\n",
    "        if \"validation\" not in raw_datasets:\n",
    "            raise ValueError(\"--do_eval requires a validation dataset\")\n",
    "        eval_dataset = raw_datasets[\"validation\"]\n",
    "        if data_args.max_eval_samples is not None:\n",
    "            eval_dataset = eval_dataset.select(range(data_args.max_eval_samples))\n",
    "        with training_args.main_process_first(desc=\"validation dataset map pre-processing\"):\n",
    "            eval_dataset = eval_dataset.map(\n",
    "                preprocess_function,\n",
    "                batched=True,\n",
    "                batch_size= training_args.train_batch_size,\n",
    "                num_proc=data_args.preprocessing_num_workers,\n",
    "                remove_columns=eval_dataset.column_names,\n",
    "                load_from_cache_file=not data_args.overwrite_cache,\n",
    "                desc=\"Running tokenizer on validation dataset\",\n",
    "            )\n",
    "\n",
    "    if training_args.do_predict:\n",
    "        max_target_length = data_args.val_max_target_length\n",
    "        if \"test\" not in raw_datasets:\n",
    "            raise ValueError(\"--do_predict requires a test dataset\")\n",
    "        predict_dataset = raw_datasets[\"test\"]\n",
    "        if data_args.max_predict_samples is not None:\n",
    "            predict_dataset = predict_dataset.select(range(data_args.max_predict_samples))\n",
    "        with training_args.main_process_first(desc=\"prediction dataset map pre-processing\"):\n",
    "            predict_dataset = predict_dataset.map(\n",
    "                preprocess_function,\n",
    "                batched=True,\n",
    "                batch_size=training_args.train_batch_size,\n",
    "                num_proc=data_args.preprocessing_num_workers,\n",
    "                remove_columns=predict_dataset.column_names,\n",
    "                load_from_cache_file=not data_args.overwrite_cache,\n",
    "                desc=\"Running tokenizer on prediction dataset\",\n",
    "            )\n",
    "\n",
    "    data_collator = DataCollatorForSeq2Seq(\n",
    "        tokenizer,\n",
    "        model=model,\n",
    "        padding=True,\n",
    "        label_pad_token_id=tokenizer.pad_token_id,\n",
    "        pad_to_multiple_of=8 if training_args.fp16 else None,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    def compute_metrics(eval_preds):\n",
    "        preds, labels = eval_preds\n",
    "        if isinstance(preds, tuple):\n",
    "            preds = preds[0]\n",
    "\n",
    "        labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    \n",
    "        decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "        \n",
    "        decoded_preds2 = [x.replace(\"$\",\"\") for x in decoded_preds]\n",
    "        decoded_labels2 = [x.replace(\"$\",\"\") for x in decoded_labels]\n",
    "        \n",
    "        sum_distance = distance(decoded_preds, decoded_labels)\n",
    "        \n",
    "        sum_distance2 = distance(decoded_preds2, decoded_labels2)\n",
    "        \n",
    "        result = {}\n",
    "        result[\"lev\"] = sum_distance\n",
    "        result[\"lev2\"] = sum_distance2\n",
    "\n",
    "        prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "        result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "        result = {k: round(v, 4) for k, v in result.items()}\n",
    "        \n",
    "        return result\n",
    "\n",
    "    # Initialize our Trainer\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset if training_args.do_train else None,\n",
    "        eval_dataset=eval_dataset if training_args.do_eval else None,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics if training_args.predict_with_generate else None,\n",
    "    )\n",
    "\n",
    "    # Training\n",
    "    if training_args.do_train:\n",
    "        checkpoint = None\n",
    "        if training_args.resume_from_checkpoint is not None:\n",
    "            checkpoint = get_last_checkpoint(training_args.output_dir)\n",
    "        \n",
    "        train_result = trainer.train(resume_from_checkpoint=checkpoint)\n",
    "        trainer.save_model() \n",
    "\n",
    "        metrics = train_result.metrics\n",
    "        max_train_samples = (\n",
    "            data_args.max_train_samples if data_args.max_train_samples is not None else len(train_dataset)\n",
    "        )\n",
    "        metrics[\"train_samples\"] = min(max_train_samples, len(train_dataset))\n",
    "\n",
    "        trainer.log_metrics(\"train\", metrics)\n",
    "        trainer.save_metrics(\"train\", metrics)\n",
    "        trainer.save_state()\n",
    "\n",
    "    # Evaluation\n",
    "    results = {}\n",
    "    max_length = (\n",
    "        training_args.generation_max_length\n",
    "        if training_args.generation_max_length is not None\n",
    "        else data_args.val_max_target_length\n",
    "    )\n",
    "    num_beams = data_args.num_beams if data_args.num_beams is not None else training_args.generation_num_beams\n",
    "\n",
    "    if training_args.do_predict:\n",
    "        logger.info(\"*** Predict ***\")\n",
    "\n",
    "        predict_results = trainer.predict(\n",
    "            predict_dataset, metric_key_prefix=\"predict\", max_length=max_length, num_beams=num_beams\n",
    "        )\n",
    "        print(\"predictions done\")\n",
    "        metrics = predict_results.metrics\n",
    "        max_predict_samples = (\n",
    "            data_args.max_predict_samples if data_args.max_predict_samples is not None else len(predict_dataset)\n",
    "        )\n",
    "        metrics[\"predict_samples\"] = min(max_predict_samples, len(predict_dataset))\n",
    "\n",
    "        results.update(metrics)\n",
    "        trainer.log_metrics(\"predict\", metrics)\n",
    "        trainer.save_metrics(\"predict\", metrics)\n",
    "        \n",
    "        print(\"will write\")\n",
    "        if trainer.is_world_process_zero():\n",
    "            if training_args.predict_with_generate:\n",
    "                predictions = tokenizer.batch_decode(\n",
    "                        predict_results.predictions, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "                    \n",
    "                )\n",
    "                predictions = [pred.strip() for pred in predictions]\n",
    "                output_prediction_file = os.path.join(training_args.output_dir, \"generated_predictions.txt\")\n",
    "                with open(output_prediction_file, \"w\", encoding=\"utf-8\") as writer:\n",
    "                    writer.write(\"\\n\".join(predictions))\n",
    "                print(\"write done\")\n",
    "    all_results_path = os.path.join(training_args.output_dir, \"all_results.json\")\n",
    "    with open(all_results_path, 'w') as f:\n",
    "        json.dump(results, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "666217c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-10T09:15:26.487801Z",
     "iopub.status.busy": "2023-03-10T09:15:26.486752Z",
     "iopub.status.idle": "2023-03-10T09:15:26.492290Z",
     "shell.execute_reply": "2023-03-10T09:15:26.491330Z"
    },
    "papermill": {
     "duration": 0.022468,
     "end_time": "2023-03-10T09:15:26.494463",
     "exception": false,
     "start_time": "2023-03-10T09:15:26.471995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# python ./run_seq2seq.py \\\n",
    "#     --model_name_or_path \"csebuetnlp/banglat5\" \\\n",
    "#     --dataset_dir \"sample_inputs/\" \\\n",
    "#     --output_dir \"outputs/\" \\\n",
    "#     --learning_rate=5e-4 \\\n",
    "#     --warmup_steps 5000 \\\n",
    "#     --label_smoothing_factor 0.1 \\\n",
    "#     --gradient_accumulation_steps 4 \\\n",
    "#     --weight_decay 0.1 \\\n",
    "#     --lr_scheduler_type \"linear\"  \\\n",
    "#     --per_device_train_batch_size=8 \\\n",
    "#     --per_device_eval_batch_size=8 \\\n",
    "#     --max_source_length 256 \\\n",
    "#     --max_target_length 256 \\\n",
    "#     --logging_strategy \"epoch\" \\\n",
    "#     --save_strategy \"epoch\" \\\n",
    "#     --evaluation_strategy \"epoch\" \\\n",
    "#     --source_key bn --target_key en \\\n",
    "#     --greater_is_better true --load_best_model_at_end \\\n",
    "#     --num_train_epochs 20 \\\n",
    "#     --do_train --do_eval --do_predict \\\n",
    "#     --predict_with_generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "658ba2ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-10T09:15:26.521957Z",
     "iopub.status.busy": "2023-03-10T09:15:26.521657Z",
     "iopub.status.idle": "2023-03-10T09:15:26.526613Z",
     "shell.execute_reply": "2023-03-10T09:15:26.525796Z"
    },
    "papermill": {
     "duration": 0.020738,
     "end_time": "2023-03-10T09:15:26.528720",
     "exception": false,
     "start_time": "2023-03-10T09:15:26.507982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !rm -rf /kaggle/working/banglat5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d26e60bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-10T09:15:26.555945Z",
     "iopub.status.busy": "2023-03-10T09:15:26.555665Z",
     "iopub.status.idle": "2023-03-10T09:15:26.566559Z",
     "shell.execute_reply": "2023-03-10T09:15:26.565755Z"
    },
    "papermill": {
     "duration": 0.0267,
     "end_time": "2023-03-10T09:15:26.568542",
     "exception": false,
     "start_time": "2023-03-10T09:15:26.541842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_args = ModelArguments(\"csebuetnlp/banglat5_small\")\n",
    "model_args = ModelArguments(\"/kaggle/input/schadenfreude-bhashabhrom/banglat5\")\n",
    "\n",
    "\n",
    "data_args = DataTrainingArguments(  dataset_dir = \"/kaggle/working/mt5_input\", \n",
    "                                    max_source_length= 256 ,\n",
    "                                    max_target_length= 256 ,\n",
    "                                 )\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"banglat5/\",\n",
    "    learning_rate=5e-4,\n",
    "    warmup_steps = 5000,\n",
    "    label_smoothing_factor= 0.1 ,\n",
    "    weight_decay =0.1 ,\n",
    "    lr_scheduler_type =\"linear\" ,\n",
    "    per_device_train_batch_size=32 ,\n",
    "    per_device_eval_batch_size=32,\n",
    "    logging_strategy= \"epoch\", \n",
    "    save_strategy =\"epoch\" ,\n",
    "    evaluation_strategy =\"epoch\",\n",
    "#     greater_is_better= False,\n",
    "#     load_best_model_at_end = True,\n",
    "#     metric_for_best_model = \"lev\" ,\n",
    "    report_to = [],\n",
    "    save_total_limit=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    resume_from_checkpoint = True,\n",
    "    num_train_epochs =  120,\n",
    "    do_train = False,\n",
    "    do_predict = True,\n",
    "    do_eval = False,\n",
    "    predict_with_generate = True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45c8ecb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-10T09:15:26.595570Z",
     "iopub.status.busy": "2023-03-10T09:15:26.595297Z",
     "iopub.status.idle": "2023-03-10T09:28:01.999506Z",
     "shell.execute_reply": "2023-03-10T09:28:01.998473Z"
    },
    "papermill": {
     "duration": 755.434851,
     "end_time": "2023-03-10T09:28:02.016341",
     "exception": false,
     "start_time": "2023-03-10T09:15:26.581490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-b9a3157292396ae9/0.0.0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "916e842de2544b0591a6487c2cf19477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5ed96f5998842d092ea452f8e4e6373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-b9a3157292396ae9/0.0.0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71c9fa0e65914c4b9a3322078b3a4971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:657] 2023-03-10 09:15:26,873 >> loading configuration file /kaggle/input/schadenfreude-bhashabhrom/banglat5/config.json\n",
      "[INFO|configuration_utils.py:708] 2023-03-10 09:15:26,878 >> Model config T5Config {\n",
      "  \"_name_or_path\": \"/kaggle/input/schadenfreude-bhashabhrom/banglat5\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32100\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1701] 2023-03-10 09:15:26,894 >> Didn't find file /kaggle/input/schadenfreude-bhashabhrom/banglat5/added_tokens.json. We won't load it.\n",
      "[INFO|tokenization_utils_base.py:1779] 2023-03-10 09:15:26,898 >> loading file /kaggle/input/schadenfreude-bhashabhrom/banglat5/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1779] 2023-03-10 09:15:26,901 >> loading file None\n",
      "[INFO|tokenization_utils_base.py:1779] 2023-03-10 09:15:26,903 >> loading file /kaggle/input/schadenfreude-bhashabhrom/banglat5/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:1779] 2023-03-10 09:15:26,906 >> loading file /kaggle/input/schadenfreude-bhashabhrom/banglat5/tokenizer_config.json\n",
      "[INFO|modeling_utils.py:2105] 2023-03-10 09:15:27,055 >> loading weights file /kaggle/input/schadenfreude-bhashabhrom/banglat5/pytorch_model.bin\n",
      "[INFO|modeling_utils.py:2483] 2023-03-10 09:15:29,554 >> All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:2492] 2023-03-10 09:15:29,555 >> All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at /kaggle/input/schadenfreude-bhashabhrom/banglat5.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8dcfe73c4a249cf914c366f6e62747c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on validation dataset:   0%|          | 0/32 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:707: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  tensor = as_tensor(value)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e50513119bc4ba5b75fec2769d18801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on prediction dataset:   0%|          | 0/157 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2753] 2023-03-10 09:15:35,150 >> ***** Running Prediction *****\n",
      "[INFO|trainer.py:2755] 2023-03-10 09:15:35,151 >>   Num examples = 5000\n",
      "[INFO|trainer.py:2758] 2023-03-10 09:15:35,154 >>   Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='157' max='157' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [157/157 02:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions done\n",
      "***** predict metrics *****\n",
      "  predict_gen_len            =    14.7906\n",
      "  predict_lev                =       5000\n",
      "  predict_lev2               =       5000\n",
      "  predict_loss               =    13.2731\n",
      "  predict_runtime            = 0:08:53.15\n",
      "  predict_samples            =       5000\n",
      "  predict_samples_per_second =      9.378\n",
      "  predict_steps_per_second   =      0.294\n",
      "will write\n",
      "write done\n"
     ]
    }
   ],
   "source": [
    "main(model_args, data_args, training_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9fff27",
   "metadata": {
    "papermill": {
     "duration": 0.017804,
     "end_time": "2023-03-10T09:28:02.054321",
     "exception": false,
     "start_time": "2023-03-10T09:28:02.036517",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Postprocessing\n",
    "\n",
    "The raw output of the model is located in banglat5/generated_predictions.txt <br>\n",
    "But as it is, the raw output has a number of issues that increase the F1 score a lot. <br>\n",
    "A naive submission of the raw t5 output results in a F1 score of in the range 3.3-3.7 <br>\n",
    "\n",
    "### Some Issues in the raw model output\n",
    "* Missing double quotes\n",
    "* Producing different unicode combinations of the same character (য় vs. য়)\n",
    "* Missing letters (কোনভাবে vs. কোনভাবেই)\n",
    "* Different spellings \n",
    "* Whole word errors (রেস্টুরেন্ট vs রেস্তোরাঁ)\n",
    "* Missing punctuation (বাতাস বন্ধু vs. ’‘ বাতাস বন্ধু)\n",
    "* Cannot handle long sentences\n",
    "* others.\n",
    "\n",
    "These need to be corrected algorithmically.\n",
    "\n",
    "\n",
    "Out of 5000 test sentences:\n",
    "* 253 were found in the provided training sets\n",
    "* 40 could not be reconciled with the t5 raw output and were handled corrected using regex\n",
    "* 4707 were predicted by the model (+ correction)\n",
    "\n",
    "The effect of each pathway is discussed in more detail in the report paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2324aa8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-10T09:28:02.085362Z",
     "iopub.status.busy": "2023-03-10T09:28:02.085011Z",
     "iopub.status.idle": "2023-03-10T09:28:02.099686Z",
     "shell.execute_reply": "2023-03-10T09:28:02.098789Z"
    },
    "papermill": {
     "duration": 0.032699,
     "end_time": "2023-03-10T09:28:02.101737",
     "exception": false,
     "start_time": "2023-03-10T09:28:02.069038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import codecs\n",
    "\n",
    "from Levenshtein import distance\n",
    "\n",
    "\n",
    "def get_bad_words(file_name):\n",
    "    '''\n",
    "    loads the words from sadhu.txt\n",
    "    Not specific to \"sadhu\" words. Should also work with common misspellings etc.\n",
    "    '''\n",
    "    bad_words = []\n",
    "    with codecs.open(file_name, encoding = 'utf8', mode='r') as f:\n",
    "        for line in f.readlines():\n",
    "            bad_words.append(line[:-2])\n",
    "    return bad_words\n",
    "\n",
    "\n",
    "def get_sorted_error_words(file_path):\n",
    "    ''' load the words from error_words.txt generated in Preporcessing '''\n",
    "    \n",
    "    sorted_error_words = []\n",
    "    with codecs.open(file_path, encoding = 'utf8', mode='r') as f:\n",
    "        for line in f.readlines():\n",
    "            \n",
    "            parts = re.split(\"-:-:-\", line)\n",
    "        \n",
    "            sorted_error_words.append((float(parts[1]), parts[0], int(parts[2]), int(parts[3])))\n",
    "    return sorted_error_words\n",
    "\n",
    "\n",
    "def regex_one_sentence(input_sentence, sorted_error_words, bad_words, threshold=0.45):\n",
    "    '''Correct a single sentence using regex. Threshold value controls which ratio of in error_words.txt to correct upto'''\n",
    "    \n",
    "    return_sentence = input_sentence\n",
    "    \n",
    "    for word in bad_words:\n",
    "        if word in return_sentence: \n",
    "            return_sentence = re.sub(re.escape(word) + r\"(?=[ !?।,])\", \"$\"+word+\"$\", return_sentence)\n",
    "    \n",
    "    for ratio,word,occ_c,err_c in sorted_error_words:\n",
    "        if word.startswith(\"$\\\"\"):\n",
    "            continue\n",
    "        if word[1:-1] in bad_words:\n",
    "            # print(\"Skipping bad word: \" + word)\n",
    "            continue\n",
    "\n",
    "        if re.fullmatch(r\"\\$[0-9]+\\$\", word):\n",
    "            # print(\"Skipping: \" + word)\n",
    "            continue\n",
    "        \n",
    "        if re.fullmatch(r\"\\$[,.\\\";*?-]+\\$\", word):\n",
    "            # print(\"Skipping: \" + word)\n",
    "            continue\n",
    "        \n",
    "\n",
    "        if ratio < threshold:\n",
    "            break\n",
    "        \n",
    "        if word[1:-1] in return_sentence:\n",
    "            # all_line[idx] = line.replace(word[1:-1], word)\n",
    "            return_sentence = re.sub(re.escape(word[1:-1]) + r\"(?=[ !?।,])\", word, return_sentence)\n",
    "        # print(word)\n",
    "    \n",
    "    file_contents = return_sentence\n",
    "\n",
    "    # file_contents = re.sub(r'-', r'$-$', file_contents)\n",
    "\n",
    "    file_contents = re.sub(r'[0-9]+', r'$\\g<0>$', file_contents)\n",
    "\n",
    "    file_contents = re.sub(r'[,.;?][,.;?]+', r'$\\g<0>$', file_contents)\n",
    "\n",
    "    file_contents = re.sub(r'\\$\\$[^ \\$]+\\$ ', lambda x: x.group(0)[1:-2]+' ', file_contents)\n",
    "\n",
    "    file_contents = re.sub(r' (?=[।?,!])', r'$ $', file_contents)\n",
    "\n",
    "    # file_contents = re.sub(r'  ', r' $ $', file_contents)\n",
    "\n",
    "    file_contents = re.sub(r'(?<=[^?!।\"])\\n', r'$$\\n', file_contents)\n",
    "    \n",
    "    file_contents = re.sub(r'(?<=[^?!।])\"\\n', r'$$\"\\n', file_contents)\n",
    "    \n",
    "    file_contents = re.sub(r' \"\\n', r'$$ \"\\n', file_contents)\n",
    "\n",
    "    # emoji_pattern = re.compile(\"[\\U0001F600-\\U0001F64F\\U0001F680-\\U0001F6FF\\U0001F700-\\U0001F77F\\U0001F780-\\U0001F7FF\\U0001F800-\\U0001F8FF\\U0001F900-\\U0001F9FF\\U0001FA00-\\U0001FA6F\\U0001FA70-\\U0001FAFF\\U00002702-\\U000027B0\\U0001F170-\\U0001F251\\U0001F004]+\")\n",
    "\n",
    "    # file_contents = emoji_pattern.sub(r'$\\g<0>$', file_contents)\n",
    "    \n",
    "    file_contents = re.sub(r'[#|৵_♥✌]+', r'$\\g<0>$', file_contents)\n",
    "    \n",
    "    file_contents = re.sub(r' ত ', r' $ত$ ', file_contents)\n",
    "\n",
    "    return file_contents\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7e8162",
   "metadata": {
    "papermill": {
     "duration": 0.014273,
     "end_time": "2023-03-10T09:28:02.131061",
     "exception": false,
     "start_time": "2023-03-10T09:28:02.116788",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Adding quotes to the generated_predictions.txt by comparing it to test_sentences.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c3809e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-10T09:28:02.162224Z",
     "iopub.status.busy": "2023-03-10T09:28:02.161875Z",
     "iopub.status.idle": "2023-03-10T09:28:02.217784Z",
     "shell.execute_reply": "2023-03-10T09:28:02.216563Z"
    },
    "papermill": {
     "duration": 0.073872,
     "end_time": "2023-03-10T09:28:02.219857",
     "exception": false,
     "start_time": "2023-03-10T09:28:02.145985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quotes added to:  1312\n"
     ]
    }
   ],
   "source": [
    "sorted_error_words = get_sorted_error_words(\"/kaggle/working/post_process/error_words.txt\")\n",
    "bad_words = get_bad_words(\"/kaggle/input/bangla-sadhu-verbs/sadhu.txt\")\n",
    "\n",
    "t5_output = \"banglat5/generated_predictions.txt\"\n",
    "train_file = \"/kaggle/working/post_process/combined.csv\"\n",
    "test_file = \"/kaggle/working/post_process/test_sentences.txt\"\n",
    "\n",
    "quoted_mt5_output = []\n",
    "quotes_added = 0\n",
    "\n",
    "with codecs.open(test_file, encoding=\"utf8\", mode='r') as f , codecs.open(t5_output, encoding=\"utf8\", mode='r') as f2:\n",
    "    \n",
    "    for line1, line2 in zip(f.readlines(), f2.readlines()):\n",
    "        line2 = line2.replace(\"\\\"\", \"\\\"\\\"\")\n",
    "        if line1[0]==\"\\\"\" and (line1[-2]==\"\\\"\" or  line1[-3]==\"\\\"\"):\n",
    "            quotes_added += 1\n",
    "            quoted_mt5_output.append(\"\\\"\"+line2[:-1]+\"\\\"\")\n",
    "        else:\n",
    "            quoted_mt5_output.append(line2[:-1])\n",
    "\n",
    "print(\"Quotes added to: \", quotes_added)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8a10f7",
   "metadata": {
    "papermill": {
     "duration": 0.014466,
     "end_time": "2023-03-10T09:28:02.249982",
     "exception": false,
     "start_time": "2023-03-10T09:28:02.235516",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Making a dictionary of  test sentences that are in the train datasets. These will be put into the final submission file as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4dc803e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-10T09:28:02.281253Z",
     "iopub.status.busy": "2023-03-10T09:28:02.280901Z",
     "iopub.status.idle": "2023-03-10T09:28:03.348540Z",
     "shell.execute_reply": "2023-03-10T09:28:03.347363Z"
    },
    "papermill": {
     "duration": 1.085727,
     "end_time": "2023-03-10T09:28:03.350639",
     "exception": false,
     "start_time": "2023-03-10T09:28:02.264912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exact_match_size:  253\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_df = pd.read_csv(train_file, encoding = 'utf8')\n",
    "\n",
    "test_lines = []\n",
    "with codecs.open(test_file, encoding = 'utf8', mode='r') as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip()\n",
    "        test_lines.append(line)\n",
    "\n",
    "        \n",
    "test_lines_set = set(test_lines)\n",
    "\n",
    "exact_match_dict = {}\n",
    "\n",
    "with codecs.open(train_file, encoding = 'utf8', mode='r') as f:\n",
    "    for tuple,codec_reading in zip(train_df.iterrows(), f.readlines()[1:]):\n",
    "        index, row = tuple\n",
    "        sentence = row[\"sentence\"]\n",
    "        gt = row[\"gt\"]\n",
    "\n",
    "        if codec_reading[0]=='\"' and codec_reading[-3]=='\"':\n",
    "            if sentence[0]!='\"' and sentence[-1]!='\"':\n",
    "                sentence = '\"'+sentence+'\"'\n",
    "                gt = '\"'+gt+'\"'\n",
    "                \n",
    "                \n",
    "        if sentence in test_lines_set:\n",
    "            exact_match_dict[sentence] = gt\n",
    "\n",
    "\n",
    "print(\"exact_match_size: \", len(exact_match_dict.keys()) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c147fb98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-10T09:28:03.383481Z",
     "iopub.status.busy": "2023-03-10T09:28:03.381824Z",
     "iopub.status.idle": "2023-03-10T09:28:03.386833Z",
     "shell.execute_reply": "2023-03-10T09:28:03.385876Z"
    },
    "papermill": {
     "duration": 0.024226,
     "end_time": "2023-03-10T09:28:03.390139",
     "exception": false,
     "start_time": "2023-03-10T09:28:03.365913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Uncomment this to essentially turn of exact matching\n",
    "# exact_match_dict={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08f5b039",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-10T09:28:03.421270Z",
     "iopub.status.busy": "2023-03-10T09:28:03.420722Z",
     "iopub.status.idle": "2023-03-10T09:28:03.425713Z",
     "shell.execute_reply": "2023-03-10T09:28:03.424787Z"
    },
    "papermill": {
     "duration": 0.022866,
     "end_time": "2023-03-10T09:28:03.427939",
     "exception": false,
     "start_time": "2023-03-10T09:28:03.405073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of dict in bytes:  9328\n"
     ]
    }
   ],
   "source": [
    "print(\"size of dict in bytes: \", sys.getsizeof(exact_match_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16757e28",
   "metadata": {
    "papermill": {
     "duration": 0.01477,
     "end_time": "2023-03-10T09:28:03.457229",
     "exception": false,
     "start_time": "2023-03-10T09:28:03.442459",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Correcting t5 output\n",
    "\n",
    "NB: This is arguably the most important step in our submission.\n",
    "The steps are:\n",
    "* Read in one sentence from t5 output and corrresponding base text from test.csv\n",
    "* If the sentence is in exact_match_dict, append it to submissions list as is\n",
    "* Otherwise, step through the sentence character by character, making corrections when necessary\n",
    "* If it fails, try whole word replacement correction\n",
    "* If word replacement correction fails as well, handle that sentence with regex_one_sentence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05d41dcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-10T09:28:03.488445Z",
     "iopub.status.busy": "2023-03-10T09:28:03.488191Z",
     "iopub.status.idle": "2023-03-10T09:28:05.716464Z",
     "shell.execute_reply": "2023-03-10T09:28:05.715228Z"
    },
    "papermill": {
     "duration": 2.246857,
     "end_time": "2023-03-10T09:28:05.718988",
     "exception": false,
     "start_time": "2023-03-10T09:28:03.472131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "couldn't correct, line_count:  23\n",
      "couldn't correct, line_count:  23\n",
      "couldn't correct, line_count:  70\n",
      "couldn't correct, line_count:  112\n",
      "couldn't correct, line_count:  112\n",
      "couldn't correct, line_count:  135\n",
      "couldn't correct, line_count:  211\n",
      "couldn't correct, line_count:  211\n",
      "couldn't correct, line_count:  318\n",
      "couldn't correct, line_count:  318\n",
      "couldn't correct, line_count:  319\n",
      "couldn't correct, line_count:  325\n",
      "couldn't correct, line_count:  385\n",
      "couldn't correct, line_count:  385\n",
      "couldn't correct, line_count:  421\n",
      "couldn't correct, line_count:  421\n",
      "couldn't correct, line_count:  431\n",
      "couldn't correct, line_count:  473\n",
      "couldn't correct, line_count:  548\n",
      "couldn't correct, line_count:  557\n",
      "couldn't correct, line_count:  599\n",
      "couldn't correct, line_count:  599\n",
      "couldn't correct, line_count:  678\n",
      "couldn't correct, line_count:  678\n",
      "couldn't correct, line_count:  685\n",
      "couldn't correct, line_count:  731\n",
      "couldn't correct, line_count:  772\n",
      "couldn't correct, line_count:  784\n",
      "couldn't correct, line_count:  817\n",
      "couldn't correct, line_count:  817\n",
      "couldn't correct, line_count:  840\n",
      "couldn't correct, line_count:  901\n",
      "couldn't correct, line_count:  964\n",
      "couldn't correct, line_count:  964\n",
      "couldn't correct, line_count:  989\n",
      "couldn't correct, line_count:  989\n",
      "couldn't correct, line_count:  1020\n",
      "couldn't correct, line_count:  1020\n",
      "couldn't correct, line_count:  1073\n",
      "couldn't correct, line_count:  1073\n",
      "couldn't correct, line_count:  1085\n",
      "couldn't correct, line_count:  1085\n",
      "couldn't correct, line_count:  1100\n",
      "couldn't correct, line_count:  1184\n",
      "couldn't correct, line_count:  1237\n",
      "couldn't correct, line_count:  1351\n",
      "couldn't correct, line_count:  1502\n",
      "couldn't correct, line_count:  1502\n",
      "couldn't correct, line_count:  1518\n",
      "couldn't correct, line_count:  1520\n",
      "couldn't correct, line_count:  1560\n",
      "couldn't correct, line_count:  1584\n",
      "couldn't correct, line_count:  1587\n",
      "couldn't correct, line_count:  1587\n",
      "couldn't correct, line_count:  1608\n",
      "couldn't correct, line_count:  1610\n",
      "couldn't correct, line_count:  1657\n",
      "couldn't correct, line_count:  1657\n",
      "couldn't correct, line_count:  1677\n",
      "couldn't correct, line_count:  1696\n",
      "couldn't correct, line_count:  1706\n",
      "couldn't correct, line_count:  1742\n",
      "couldn't correct, line_count:  1742\n",
      "couldn't correct, line_count:  1771\n",
      "couldn't correct, line_count:  1771\n",
      "couldn't correct, line_count:  1790\n",
      "couldn't correct, line_count:  1790\n",
      "couldn't correct, line_count:  1860\n",
      "couldn't correct, line_count:  1860\n",
      "couldn't correct, line_count:  1899\n",
      "couldn't correct, line_count:  1980\n",
      "couldn't correct, line_count:  1990\n",
      "couldn't correct, line_count:  1990\n",
      "couldn't correct, line_count:  1998\n",
      "couldn't correct, line_count:  2002\n",
      "couldn't correct, line_count:  2036\n",
      "couldn't correct, line_count:  2036\n",
      "couldn't correct, line_count:  2083\n",
      "couldn't correct, line_count:  2083\n",
      "couldn't correct, line_count:  2118\n",
      "couldn't correct, line_count:  2158\n",
      "couldn't correct, line_count:  2158\n",
      "couldn't correct, line_count:  2188\n",
      "couldn't correct, line_count:  2264\n",
      "couldn't correct, line_count:  2267\n",
      "couldn't correct, line_count:  2267\n",
      "couldn't correct, line_count:  2301\n",
      "couldn't correct, line_count:  2301\n",
      "couldn't correct, line_count:  2321\n",
      "couldn't correct, line_count:  2328\n",
      "couldn't correct, line_count:  2344\n",
      "couldn't correct, line_count:  2376\n",
      "couldn't correct, line_count:  2376\n",
      "couldn't correct, line_count:  2388\n",
      "couldn't correct, line_count:  2403\n",
      "couldn't correct, line_count:  2403\n",
      "couldn't correct, line_count:  2411\n",
      "couldn't correct, line_count:  2480\n",
      "couldn't correct, line_count:  2632\n",
      "couldn't correct, line_count:  2641\n",
      "couldn't correct, line_count:  2686\n",
      "couldn't correct, line_count:  2707\n",
      "couldn't correct, line_count:  2729\n",
      "couldn't correct, line_count:  2752\n",
      "couldn't correct, line_count:  2752\n",
      "couldn't correct, line_count:  2874\n",
      "couldn't correct, line_count:  3013\n",
      "couldn't correct, line_count:  3030\n",
      "couldn't correct, line_count:  3052\n",
      "couldn't correct, line_count:  3167\n",
      "couldn't correct, line_count:  3167\n",
      "couldn't correct, line_count:  3200\n",
      "couldn't correct, line_count:  3200\n",
      "couldn't correct, line_count:  3367\n",
      "couldn't correct, line_count:  3397\n",
      "couldn't correct, line_count:  3407\n",
      "couldn't correct, line_count:  3407\n",
      "couldn't correct, line_count:  3482\n",
      "couldn't correct, line_count:  3487\n",
      "couldn't correct, line_count:  3487\n",
      "couldn't correct, line_count:  3537\n",
      "couldn't correct, line_count:  3537\n",
      "couldn't correct, line_count:  3562\n",
      "couldn't correct, line_count:  3571\n",
      "couldn't correct, line_count:  3571\n",
      "couldn't correct, line_count:  3623\n",
      "couldn't correct, line_count:  3724\n",
      "couldn't correct, line_count:  3751\n",
      "couldn't correct, line_count:  3751\n",
      "couldn't correct, line_count:  3761\n",
      "couldn't correct, line_count:  3761\n",
      "couldn't correct, line_count:  3787\n",
      "couldn't correct, line_count:  3787\n",
      "couldn't correct, line_count:  3923\n",
      "couldn't correct, line_count:  3955\n",
      "couldn't correct, line_count:  4103\n",
      "couldn't correct, line_count:  4103\n",
      "couldn't correct, line_count:  4109\n",
      "couldn't correct, line_count:  4136\n",
      "couldn't correct, line_count:  4136\n",
      "couldn't correct, line_count:  4143\n",
      "couldn't correct, line_count:  4164\n",
      "couldn't correct, line_count:  4164\n",
      "couldn't correct, line_count:  4168\n",
      "couldn't correct, line_count:  4172\n",
      "couldn't correct, line_count:  4172\n",
      "couldn't correct, line_count:  4218\n",
      "couldn't correct, line_count:  4218\n",
      "couldn't correct, line_count:  4227\n",
      "couldn't correct, line_count:  4227\n",
      "couldn't correct, line_count:  4279\n",
      "couldn't correct, line_count:  4279\n",
      "couldn't correct, line_count:  4294\n",
      "couldn't correct, line_count:  4296\n",
      "couldn't correct, line_count:  4296\n",
      "couldn't correct, line_count:  4301\n",
      "couldn't correct, line_count:  4316\n",
      "couldn't correct, line_count:  4430\n",
      "couldn't correct, line_count:  4430\n",
      "couldn't correct, line_count:  4476\n",
      "couldn't correct, line_count:  4476\n",
      "couldn't correct, line_count:  4509\n",
      "couldn't correct, line_count:  4521\n",
      "couldn't correct, line_count:  4521\n",
      "couldn't correct, line_count:  4539\n",
      "couldn't correct, line_count:  4545\n",
      "couldn't correct, line_count:  4545\n",
      "couldn't correct, line_count:  4570\n",
      "couldn't correct, line_count:  4570\n",
      "couldn't correct, line_count:  4594\n",
      "couldn't correct, line_count:  4595\n",
      "couldn't correct, line_count:  4918\n",
      "couldn't correct, line_count:  4962\n",
      "Regexed Sentences # 52\n",
      "Exact Match Sentences # 253\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import codecs\n",
    "import re\n",
    "import sys\n",
    "from Levenshtein import distance\n",
    "\n",
    "utostio1_ = \"য়\"\n",
    "utostio2 = \"য়\"\n",
    "dor1_ = \"ড়\"\n",
    "dor2 = \"ড়\"\n",
    "dhor1_ = \"ঢ়\"\n",
    "dhor2 = \"ঢ়\"\n",
    "akar1 = \"া\"\n",
    "roshikar1 = \"ি\"\n",
    "dirghikar1 = \"ী\"\n",
    "roshaukar1 =\"ু\"\n",
    "dirghuukar1 = \"ূ\"\n",
    "eekar1 = \"ে\"\n",
    "oikar1 = \"ৈ\"\n",
    "okar1_ = \"ো\"\n",
    "okar2 = \"ো\"\n",
    "aukar1_ = \"ৌ\"\n",
    "aukar2 = \"ৌ\"\n",
    "dontonaw1 = \"ন\"\n",
    "moddhonno = \"ণ\"\n",
    "\n",
    "REGEX_ERROR_THRESHOLD = 0.5\n",
    "# used in regex_one_sentence(). if err_count/occ_count < 0.5, dont correct it\n",
    "\n",
    "\n",
    "first_step_output = []\n",
    "\n",
    "def t5_tendency(line,line2):\n",
    "    ''' This function is called when all character level corrects fail. It attempts a word level correction and tries again'''\n",
    "\n",
    "    line_t = line.replace(\"$\", \"\")\n",
    "    line_t = line_t.strip()\n",
    "    line_t = line_t.replace(\"য়\", \"য়\")\n",
    "    line_t = line_t.replace(\"ো\", \"ো\")\n",
    "    line_t = line_t.replace(\"ড়\", \"ড়\")\n",
    "    line_t = line_t.replace(\"ঢ়\", \"ঢ়\")\n",
    "\n",
    "    line_t2 = line2.replace(\"$\", \"\")\n",
    "    line_t2 = line_t2.replace(\"য়\", \"য়\")\n",
    "    line_t2 = line_t2.replace(\"ো\", \"ো\")\n",
    "    line_t2 = line_t2.replace(\"ড়\", \"ড়\")\n",
    "    line_t2 = line_t2.replace(\"ঢ়\", \"ঢ়\")\n",
    "\n",
    "    words1 = line_t.split()\n",
    "    words2 = line_t2.split()\n",
    "\n",
    "    indexes = []\n",
    "    count = 0\n",
    "    for  word1, word2 in zip(words1, words2):\n",
    "        if word1 != word2:\n",
    "            indexes.append(count)\n",
    "        count += 1\n",
    "    \n",
    "    for index in indexes:\n",
    "        line = line.replace(words1[index], words2[index])\n",
    "    \n",
    "    return line\n",
    "\n",
    "\n",
    "line_count = 0\n",
    "error_count = 0\n",
    "exact_match_count = 0\n",
    "\n",
    "\n",
    "\n",
    "for line1, line2 in zip(quoted_mt5_output, test_lines):\n",
    "    line1+=\"\\n\"\n",
    "    line2+=\"\\n\"\n",
    "    line_count += 1\n",
    "       \n",
    "    #modest improvement: private 1.072->1.0224 public 1.0988->1.0588\n",
    "    if line2.strip() in exact_match_dict.keys():\n",
    "        first_step_output.append(exact_match_dict[line2.strip()]+\"\\n\")\n",
    "#         print(exact_match_dict[line2.strip()])\n",
    "        exact_match_count+=1\n",
    "        continue\n",
    "\n",
    "    index1 = 0\n",
    "    index2 = 0\n",
    "    error_flag = False\n",
    "    new_line1 = ''\n",
    "    chance = 1\n",
    "    while True:\n",
    "        if index1 >= len(line1) or index2 >= len(line2):\n",
    "            break\n",
    "\n",
    "        if line1[index1] == '$':\n",
    "            #print(\"--1--\")\n",
    "            new_line1 += \"$\"\n",
    "            index1 += 1\n",
    "            continue\n",
    "\n",
    "        if line1[index1] == line2[index2]:\n",
    "            #print(\"--2--\")\n",
    "            new_line1 += line1[index1]\n",
    "            index1 += 1\n",
    "            index2 += 1\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        \n",
    "        if line1[index1] == \"ু\".strip() and line2[index2] == \"ূ\".strip():\n",
    "            new_line1 += \"ূ\"\n",
    "            index1 += 1\n",
    "            index2 += 1\n",
    "            continue\n",
    "\n",
    "        if line1[index1] == \"ূ\".strip() and line2[index2] == \"ু\".strip():\n",
    "            new_line1 += \"ু\"\n",
    "            index1 += 1\n",
    "            index2 += 1\n",
    "            continue\n",
    "        if line1[index1] == roshaukar1 and line2[index2] == okar1_:\n",
    "            new_line1 += okar1_\n",
    "            index1 += 1\n",
    "            index2 += 1\n",
    "            continue\n",
    "        if line1[index1] == roshaukar1 and line2[index2] == okar2:\n",
    "            new_line1 += okar2\n",
    "            index1 += 1\n",
    "            index2 += 1\n",
    "            continue\n",
    "\n",
    "        if line1[index1] == akar1 and line2[index2] == roshikar1:\n",
    "            new_line1 += roshikar1\n",
    "            index1 += 1\n",
    "            index2 += 1\n",
    "            continue\n",
    "\n",
    "        if line1[index1] == roshikar1 and line2[index2] == akar1:\n",
    "            new_line1 += akar1\n",
    "            index1 += 1\n",
    "            index2 += 1\n",
    "            continue\n",
    "\n",
    "        if line1[index1] == roshikar1 and line2[index2] == dirghikar1:\n",
    "            new_line1 += dirghikar1\n",
    "            index1 += 1\n",
    "            index2 += 1\n",
    "            continue\n",
    "            \n",
    "        if line1[index1] == dirghikar1 and line2[index2] == roshikar1:\n",
    "            new_line1 += roshikar1\n",
    "            index1 += 1\n",
    "            index2 += 1\n",
    "            continue\n",
    "\n",
    "        if line1[index1] == dontonaw1 and line2[index2] == moddhonno:\n",
    "            new_line1 += moddhonno\n",
    "            index1 += 1\n",
    "            index2 += 1\n",
    "            continue\n",
    "\n",
    "        if line1[index1] == moddhonno and line2[index2] == dontonaw1:\n",
    "            new_line1 += dontonaw1\n",
    "            index1 += 1\n",
    "            index2 += 1\n",
    "            continue\n",
    "\n",
    "        if line1[index1] == roshikar1 and line2[index2] == eekar1:\n",
    "            new_line1 += eekar1\n",
    "            index1 += 1\n",
    "            index2 += 1\n",
    "            continue\n",
    "\n",
    "        if line1[index1] == eekar1 and line2[index2] == roshikar1:\n",
    "            new_line1 += roshikar1\n",
    "            index1 += 1\n",
    "            index2 += 1\n",
    "            continue\n",
    "\n",
    "        if line1[index1] == eekar1 and line2[index2] == akar1:\n",
    "            new_line1 += akar1\n",
    "            index1 += 1\n",
    "            index2 += 1\n",
    "            continue\n",
    "\n",
    "        if line1[index1] == akar1 and line2[index2] == eekar1:\n",
    "            new_line1 += eekar1\n",
    "            index1 += 1\n",
    "            index2 += 1\n",
    "            continue\n",
    "\n",
    "        if line1[index1] == eekar1 and line2[index2] == dirghikar1:\n",
    "            new_line1 += dirghikar1\n",
    "            index1 += 1\n",
    "            index2 += 1\n",
    "            continue\n",
    "\n",
    "        if line1[index1] == dirghikar1 and line2[index2] == eekar1:\n",
    "            new_line1 += eekar1\n",
    "            index1 += 1\n",
    "            index2 += 1\n",
    "            continue\n",
    "\n",
    "        if (line1[index1] == okar1_ or line1[index1] == okar2) and line2[index2] == akar1:\n",
    "            new_line1 += akar1\n",
    "            index1 += 1\n",
    "            index2 += 1\n",
    "            continue\n",
    "\n",
    "        if line1[index1] == akar1 and (line1[index1] == okar1_ or line1[index1] == okar2):\n",
    "            new_line1 += line1[index1]\n",
    "            index1 += 1\n",
    "            index2 += 1\n",
    "            continue\n",
    "\n",
    "        allowed = [\"?\", \"…\",\"!\",\"*\",\"ু\",\" ূ\",\"ঁ\", \"।\", \"\\n\",\",\",\"-\",\"\\\"\",\".\", \" \",\"!\",\"?\",\"।\", \"“\", \"—\", \"”\", \".\", \"‘\", \"–\", \"’\", \"*\", ]\n",
    "\n",
    "        if line2[index2] in allowed:\n",
    "            new_line1 += line2[index2]\n",
    "            index2 += 1\n",
    "            continue\n",
    "\n",
    "        problematic = [\"♥\",\"✌\",\"✔\",\"♣\"]\n",
    "\n",
    "        if line2[index2] in problematic:\n",
    "            new_line1 += (\"$\"+line2[index2]+\"$\")\n",
    "            index2 += 1\n",
    "            continue\n",
    "        \n",
    "\n",
    "        if line2[index2] == \" \":\n",
    "            new_line1 += line2[index2]\n",
    "            index2 += 1\n",
    "            # index2 += 1\n",
    "            continue\n",
    "        \n",
    "        if line1[index1] in [\" \", \"ঁ\",\"?\",\"’\",\"।\", \"✔\",\"'\",\"\\\"\", \"-\",\",\",\".\"]:\n",
    "            index1 += 1\n",
    "            continue\n",
    "\n",
    "        if line1[index1] == \"\\n\":\n",
    "            new_line1 += line2[index2:]\n",
    "            break\n",
    "\n",
    "        if line1[index1:index1+2] == utostio1_ and line2[index2] == utostio2:\n",
    "            #print(\"--3--\")\n",
    "            new_line1 += utostio2\n",
    "            index1 += 2\n",
    "            index2 += 1\n",
    "            continue\n",
    "            \n",
    "        if line1[index1] == utostio2 and line2[index2:index2+2] == utostio1_:\n",
    "            #print(\"--4--\")\n",
    "            new_line1 += utostio1_\n",
    "            index1 += 1\n",
    "            index2 += 2\n",
    "            continue\n",
    "\n",
    "        if line1[index1:index1+2] == okar1_ and line2[index2] == okar2:\n",
    "            #print(\"--5--\")\n",
    "            new_line1 += okar2\n",
    "            index1 += 2\n",
    "            index2 += 1\n",
    "            continue\n",
    "        \n",
    "        if line1[index1] == okar2 and line2[index2:index2+2] == okar1_:\n",
    "            #print(\"--6--\")\n",
    "            new_line1 += okar1_\n",
    "            index1 += 1\n",
    "            index2 += 2\n",
    "            continue\n",
    "\n",
    "        if line1[index1:index1+2] == aukar1_ and line2[index2] == aukar2:\n",
    "            #print(\"--7--\")\n",
    "            new_line1 += aukar2\n",
    "            index1 += 2\n",
    "            index2 += 1\n",
    "            continue\n",
    "\n",
    "        if line1[index1] == aukar2 and line2[index2:index2+2] == aukar1_:\n",
    "            #print(\"--8--\")\n",
    "            new_line1 += aukar1_\n",
    "            index1 += 1\n",
    "            index2 += 2\n",
    "            continue\n",
    "\n",
    "        if line1[index1:index1+2] == dor1_ and line2[index2] == dor2:\n",
    "            #print(\"--7--\")\n",
    "            new_line1 += dor2\n",
    "            index1 += 2\n",
    "            index2 += 1\n",
    "            continue\n",
    "\n",
    "        if line1[index1] == dor2 and line2[index2:index2+2] == dor1_:\n",
    "            #print(\"--8--\")\n",
    "            new_line1 += dor1_\n",
    "            index1 += 1\n",
    "            index2 += 2\n",
    "            continue\n",
    "            \n",
    "        if line1[index1:index1+2] == dhor1_ and line2[index2] == dhor2:\n",
    "            #print(\"--9--\")\n",
    "            new_line1 += dhor2\n",
    "            index1 += 2\n",
    "            index2 += 1\n",
    "            continue\n",
    "\n",
    "        if line1[index1] == dhor2 and line2[index2:index2+2] == dhor1_:\n",
    "            #print(\"--10--\")\n",
    "            new_line1 += dhor1_\n",
    "            index1 += 1\n",
    "            index2 += 2\n",
    "            continue\n",
    "        \n",
    "        print(\"couldn't correct, line_count: \", line_count)\n",
    "#         print(\"error\", line1[index1],\"  &   \", line2[index2])\n",
    "#         print(\"error\", line1[index1:index1+2],\"  &   \", line2[index2])\n",
    "#         print(\"error\", line1[index1],\"  &   \", line2[index2:index2+2])\n",
    "        \n",
    "#         print(line_count)\n",
    "\n",
    "        #trying to repair\n",
    "        if chance == 1:\n",
    "            line1 = t5_tendency(line1,line2)\n",
    "            index1 = 0\n",
    "            index2 = 0\n",
    "            new_line1 = ''\n",
    "            chance = 0    #try word level correction only once\n",
    "            continue\n",
    "            \n",
    "        error_flag = True\n",
    "        error_count += 1\n",
    "        break\n",
    "   \n",
    "    if error_flag:\n",
    "        first_step_output.append(regex_one_sentence(line2, sorted_error_words, bad_words, threshold=REGEX_ERROR_THRESHOLD))   \n",
    "       \n",
    "    else:\n",
    "        first_step_output.append(new_line1)   \n",
    "\n",
    "print(\"Regexed Sentences #\", error_count)  \n",
    "print(\"Exact Match Sentences #\", exact_match_count)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83b65549",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-10T09:28:05.754667Z",
     "iopub.status.busy": "2023-03-10T09:28:05.752861Z",
     "iopub.status.idle": "2023-03-10T09:28:05.758894Z",
     "shell.execute_reply": "2023-03-10T09:28:05.757812Z"
    },
    "papermill": {
     "duration": 0.025394,
     "end_time": "2023-03-10T09:28:05.760842",
     "exception": false,
     "start_time": "2023-03-10T09:28:05.735448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "print(len(first_step_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f352c75",
   "metadata": {
    "papermill": {
     "duration": 0.015654,
     "end_time": "2023-03-10T09:28:05.792456",
     "exception": false,
     "start_time": "2023-03-10T09:28:05.776802",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Alogorithmic Improvements on T5 Predictions\n",
    "Corrections against sadhu.txt were made only for sentences handled with regex. T5 on its own misses a few of these words which can optionally be corrected. Not a significant improvement in any case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5dc44504",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-10T09:28:05.826406Z",
     "iopub.status.busy": "2023-03-10T09:28:05.825478Z",
     "iopub.status.idle": "2023-03-10T09:28:11.436784Z",
     "shell.execute_reply": "2023-03-10T09:28:11.435676Z"
    },
    "papermill": {
     "duration": 5.630712,
     "end_time": "2023-03-10T09:28:11.439010",
     "exception": false,
     "start_time": "2023-03-10T09:28:05.808298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:05<00:00, 893.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2nd step correction count:  14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#very slight improvement in public score 1.0588 -> 1.0564\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "second_step_output = []\n",
    "\n",
    "line_count = 0\n",
    "corrections_made = 0\n",
    "\n",
    "for line in tqdm(first_step_output):\n",
    "    to_append = line\n",
    "    if line.strip().replace(\"$\",\"\") in exact_match_dict.keys():\n",
    "        second_step_output.append(to_append)  \n",
    "        line_count += 1\n",
    "        continue\n",
    "\n",
    "    for word in bad_words:\n",
    "        if re.search(r\"(?<=[ !?।,\\\"])\"+re.escape(word) + r\"(?=[ !?।,\\\"])\", line):\n",
    "            if \"$\"+word+\"$\" not in line:\n",
    "                to_append = line.replace(word, \"$\"+word+\"$\")\n",
    "                corrections_made +=1\n",
    "\n",
    "# #   This actually degrades F1 score and is slow to as well.\n",
    "#     for ratio,word,occ_c,err_c in sorted_error_words:\n",
    "        \n",
    "#         if occ_c == 1 and err_c!=1:\n",
    "#             continue\n",
    "            \n",
    "#         if word == \"$\\\"আমি$\":\n",
    "#             continue\n",
    "#         if word[1:-1] in bad_words:\n",
    "#             continue\n",
    "\n",
    "#         if re.fullmatch(r\"\\$[0-9]+\\$\", word):\n",
    "#             continue\n",
    "\n",
    "#         if re.fullmatch(r\"\\$[,.;*?-]+\\$\", word):\n",
    "#             continue\n",
    "\n",
    "#         if ratio < 1:\n",
    "#             break\n",
    "\n",
    "#         allowed = [\" \" , \"!\", \"?\", \",\", \"।\", '\"']\n",
    "#         for x in allowed:\n",
    "#             for y in allowed:\n",
    "#                 if x+word[1:-1]+y in to_append and word not in to_append:\n",
    "#                     to_append = to_append.replace(\" \"+word[1:-1]+\" \",\" \"+word+\" \")\n",
    "#                     corrections_made +=1\n",
    "#                     break\n",
    "\n",
    "    second_step_output.append(to_append)\n",
    "    line_count += 1\n",
    "\n",
    "print(\"2nd step correction count: \", corrections_made)     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22df4756",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-10T09:28:11.479919Z",
     "iopub.status.busy": "2023-03-10T09:28:11.478407Z",
     "iopub.status.idle": "2023-03-10T09:28:11.487864Z",
     "shell.execute_reply": "2023-03-10T09:28:11.486741Z"
    },
    "papermill": {
     "duration": 0.031411,
     "end_time": "2023-03-10T09:28:11.489733",
     "exception": false,
     "start_time": "2023-03-10T09:28:11.458322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "print(len(second_step_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e6148b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-10T09:28:11.529475Z",
     "iopub.status.busy": "2023-03-10T09:28:11.528502Z",
     "iopub.status.idle": "2023-03-10T09:28:11.535340Z",
     "shell.execute_reply": "2023-03-10T09:28:11.534276Z"
    },
    "papermill": {
     "duration": 0.028608,
     "end_time": "2023-03-10T09:28:11.537425",
     "exception": false,
     "start_time": "2023-03-10T09:28:11.508817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ব্যক্তি থেকেই শুরু যার সমাপ্তি হবে বিশ্বে মুসলিমদের মহত্ত্বের চর্চায় যেমনটি আগে ছিল রাসূলের আদর্শে আছে।\\n',\n",
       " '\"ইউনিটগণ, পিছিয়ে যান।\"\\n',\n",
       " 'ভিক্টোরিয়ার ক্লেটন ক্যাম্পাসে ছয়টি আবাসিক হল রয়েছে।\\n',\n",
       " 'তেমনি আবির একটা বইপোঁকা সেটা বললে ভুল $হবেনা$।\\n',\n",
       " 'আমরা চাই গরিব চাচা যেন $তারনেয্য$ টাকা $পিরে$ পায় এবং সারা $বাংলাদেসে$ যমুনা টিবির সুনাম বয়ে $জায়$$$\\n']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_step_output[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c8ef66",
   "metadata": {
    "papermill": {
     "duration": 0.018813,
     "end_time": "2023-03-10T09:28:11.575531",
     "exception": false,
     "start_time": "2023-03-10T09:28:11.556718",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Writing to file submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ad42253",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-10T09:28:11.614451Z",
     "iopub.status.busy": "2023-03-10T09:28:11.614174Z",
     "iopub.status.idle": "2023-03-10T09:28:11.626433Z",
     "shell.execute_reply": "2023-03-10T09:28:11.625546Z"
    },
    "papermill": {
     "duration": 0.033906,
     "end_time": "2023-03-10T09:28:11.628376",
     "exception": false,
     "start_time": "2023-03-10T09:28:11.594470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "output_file = \"post_processed_predictions.txt\"\n",
    "with codecs.open(output_file, mode='w', encoding=\"utf8\") as f:\n",
    "    for line in second_step_output:\n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d30258f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-10T09:28:11.667966Z",
     "iopub.status.busy": "2023-03-10T09:28:11.667044Z",
     "iopub.status.idle": "2023-03-10T09:28:12.684604Z",
     "shell.execute_reply": "2023-03-10T09:28:12.683321Z"
    },
    "papermill": {
     "duration": 1.040412,
     "end_time": "2023-03-10T09:28:12.687632",
     "exception": false,
     "start_time": "2023-03-10T09:28:11.647220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\r\n",
      "all_results.json  generated_predictions.txt  predict_results.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls /kaggle/working/banglat5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da557a15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-10T09:28:12.728913Z",
     "iopub.status.busy": "2023-03-10T09:28:12.727839Z",
     "iopub.status.idle": "2023-03-10T09:28:12.735512Z",
     "shell.execute_reply": "2023-03-10T09:28:12.734408Z"
    },
    "papermill": {
     "duration": 0.030366,
     "end_time": "2023-03-10T09:28:12.737557",
     "exception": false,
     "start_time": "2023-03-10T09:28:12.707191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='banglat5/generated_predictions.txt' target='_blank'>banglat5/generated_predictions.txt</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/banglat5/generated_predictions.txt"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(r'banglat5/generated_predictions.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "84767a47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-10T09:28:12.777398Z",
     "iopub.status.busy": "2023-03-10T09:28:12.776594Z",
     "iopub.status.idle": "2023-03-10T09:28:12.783009Z",
     "shell.execute_reply": "2023-03-10T09:28:12.782044Z"
    },
    "papermill": {
     "duration": 0.028272,
     "end_time": "2023-03-10T09:28:12.784979",
     "exception": false,
     "start_time": "2023-03-10T09:28:12.756707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='post_process/test_sentences.txt' target='_blank'>post_process/test_sentences.txt</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/post_process/test_sentences.txt"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileLink(r'post_process/test_sentences.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b6b4666",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-10T09:28:12.825188Z",
     "iopub.status.busy": "2023-03-10T09:28:12.824381Z",
     "iopub.status.idle": "2023-03-10T09:28:12.830691Z",
     "shell.execute_reply": "2023-03-10T09:28:12.829725Z"
    },
    "papermill": {
     "duration": 0.028494,
     "end_time": "2023-03-10T09:28:12.832803",
     "exception": false,
     "start_time": "2023-03-10T09:28:12.804309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='post_processed_predictions.txt' target='_blank'>post_processed_predictions.txt</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/post_processed_predictions.txt"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileLink(r'post_processed_predictions.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d1ea450",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-10T09:28:12.873423Z",
     "iopub.status.busy": "2023-03-10T09:28:12.872537Z",
     "iopub.status.idle": "2023-03-10T09:28:12.908941Z",
     "shell.execute_reply": "2023-03-10T09:28:12.908083Z"
    },
    "papermill": {
     "duration": 0.059071,
     "end_time": "2023-03-10T09:28:12.911174",
     "exception": false,
     "start_time": "2023-03-10T09:28:12.852103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "with codecs.open(output_file, encoding=\"utf8\") as f:\n",
    "    with codecs.open(\"submission.csv\", mode='w', encoding=\"utf8\") as f1:\n",
    "        index = 1\n",
    "        f1.write(\"Id,Expected\\n\")\n",
    "        for line in f.readlines():\n",
    "            f1.write(str(index) + \",\" + line)\n",
    "            index += 1\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "29bd95c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-10T09:28:12.951844Z",
     "iopub.status.busy": "2023-03-10T09:28:12.950985Z",
     "iopub.status.idle": "2023-03-10T09:28:12.957237Z",
     "shell.execute_reply": "2023-03-10T09:28:12.956430Z"
    },
    "papermill": {
     "duration": 0.028154,
     "end_time": "2023-03-10T09:28:12.959013",
     "exception": false,
     "start_time": "2023-03-10T09:28:12.930859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='submission.csv' target='_blank'>submission.csv</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/submission.csv"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(r'submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53811f06",
   "metadata": {
    "papermill": {
     "duration": 0.019473,
     "end_time": "2023-03-10T09:28:12.998027",
     "exception": false,
     "start_time": "2023-03-10T09:28:12.978554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 879.656322,
   "end_time": "2023-03-10T09:28:16.729310",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-10T09:13:37.072988",
   "version": "2.3.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "004224f53884497082151b2c406edc19": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "0074d3a10b314b13a388f05d0587f97c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "127f22cc4df149f5a952bf68a56aa7ed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0074d3a10b314b13a388f05d0587f97c",
       "placeholder": "​",
       "style": "IPY_MODEL_6a7091ae2c304668af1e8575891f36e1",
       "value": " 3/3 [00:00&lt;00:00, 47.00it/s]"
      }
     },
     "1288250ef64a48db91f71a1c47f60a4b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "207f5b1d97654c02aebd94f0b6bcea53": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2159a87df9da44bda31da27425dd1908": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "254eef52aec447a3b1e2eddf93a1f966": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c1114ecf713441bfbd7e7489f67373a0",
       "placeholder": "​",
       "style": "IPY_MODEL_eeba02b863514920af94e2f0f1f7d1d8",
       "value": " 157/157 [00:01&lt;00:00, 119.76ba/s]"
      }
     },
     "2d9457a32b2e4eb28bb04ba66a169905": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1288250ef64a48db91f71a1c47f60a4b",
       "placeholder": "​",
       "style": "IPY_MODEL_de8cec17333c42e58028e1cbb5c76bc6",
       "value": "Running tokenizer on prediction dataset: 100%"
      }
     },
     "3835d7beffb140dca1fc9423439a34ba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3aea413ffd7e406fb758447209338387": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5ac4208ce1654da1bf20e867448f2a29",
       "max": 3.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c73aee01ec114fb49729ee087e345e18",
       "value": 3.0
      }
     },
     "413bc423936042e9a1cd4fa7c6a384e1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_92bd4a2bfc134a448036eaa91f0694fe",
       "placeholder": "​",
       "style": "IPY_MODEL_51977270442b429fa6c835d5ef41eb4a",
       "value": " 3/3 [00:00&lt;00:00, 69.02it/s]"
      }
     },
     "4274c1ed65ff4033aa564020517a09d4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7e4962d24a1e4c4a8564749396581dbf",
       "max": 3.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d39a2be7135c4577a46d2f2883601e62",
       "value": 3.0
      }
     },
     "44c3926a804a46ba98f599aeeda2e2e0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4e50513119bc4ba5b75fec2769d18801": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2d9457a32b2e4eb28bb04ba66a169905",
        "IPY_MODEL_d937e516b2e14876b70b25a8c7c7b58c",
        "IPY_MODEL_254eef52aec447a3b1e2eddf93a1f966"
       ],
       "layout": "IPY_MODEL_efd00f044dfa40c7a9c25662e0829a17"
      }
     },
     "51977270442b429fa6c835d5ef41eb4a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "53aa3d4d4343487b8608e72c491f43f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "54ae53b5871541898726ca9d36c96187": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e5290c56af2d4f479b04800566e68e12",
       "placeholder": "​",
       "style": "IPY_MODEL_2159a87df9da44bda31da27425dd1908",
       "value": "Running tokenizer on validation dataset: 100%"
      }
     },
     "587497bde5d3432f9f4143380bef7c92": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8c7d1acfaaaa47489224765f1ae33e25",
       "placeholder": "​",
       "style": "IPY_MODEL_a6c7ea1969614488b3d56da47a214e95",
       "value": "Extracting data files: 100%"
      }
     },
     "5ac4208ce1654da1bf20e867448f2a29": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5af164b9ef114822b7abb41a0b54d004": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_88edf3ba6a7a40548f30bb355361d807",
       "placeholder": "​",
       "style": "IPY_MODEL_53aa3d4d4343487b8608e72c491f43f6",
       "value": " 32/32 [00:00&lt;00:00, 76.03ba/s]"
      }
     },
     "66e4106f254e47a5bf903c1df2d825d7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9d54e5a1747e49219dbf2eb16eb22eda",
       "placeholder": "​",
       "style": "IPY_MODEL_004224f53884497082151b2c406edc19",
       "value": " 3/3 [00:00&lt;00:00, 52.51it/s]"
      }
     },
     "6a7091ae2c304668af1e8575891f36e1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "71c9fa0e65914c4b9a3322078b3a4971": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_967c5819d9d143f1b9ec32ebd0f42f58",
        "IPY_MODEL_4274c1ed65ff4033aa564020517a09d4",
        "IPY_MODEL_66e4106f254e47a5bf903c1df2d825d7"
       ],
       "layout": "IPY_MODEL_d7498c633b3f4da8994f8c6dc169ae1c"
      }
     },
     "7e4962d24a1e4c4a8564749396581dbf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "82f9e445654345bbb8eb8d74fe217f6d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "85b83c865d874e2c9a4d246ce31a7538": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "88edf3ba6a7a40548f30bb355361d807": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8b01ea5b4e344128b1af4d95e8f1d47f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8c7d1acfaaaa47489224765f1ae33e25": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "916e842de2544b0591a6487c2cf19477": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f69dedf64ab34659a7cc58b6ecbf7373",
        "IPY_MODEL_3aea413ffd7e406fb758447209338387",
        "IPY_MODEL_413bc423936042e9a1cd4fa7c6a384e1"
       ],
       "layout": "IPY_MODEL_e6f492e2a23f4643b84f18392177ec2c"
      }
     },
     "92bd4a2bfc134a448036eaa91f0694fe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "967c5819d9d143f1b9ec32ebd0f42f58": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_85b83c865d874e2c9a4d246ce31a7538",
       "placeholder": "​",
       "style": "IPY_MODEL_44c3926a804a46ba98f599aeeda2e2e0",
       "value": "100%"
      }
     },
     "9d54e5a1747e49219dbf2eb16eb22eda": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9f69d981d316460c904f9d105980ddb0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_82f9e445654345bbb8eb8d74fe217f6d",
       "max": 3.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3835d7beffb140dca1fc9423439a34ba",
       "value": 3.0
      }
     },
     "a6c7ea1969614488b3d56da47a214e95": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a9c0a1baed9c416b8b271f4049f98320": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ab2c55d204d04993969f75420aa9a538": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ba00a20aabb44d9d943d6a58c952b4c1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c1114ecf713441bfbd7e7489f67373a0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c5ed96f5998842d092ea452f8e4e6373": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_587497bde5d3432f9f4143380bef7c92",
        "IPY_MODEL_9f69d981d316460c904f9d105980ddb0",
        "IPY_MODEL_127f22cc4df149f5a952bf68a56aa7ed"
       ],
       "layout": "IPY_MODEL_cc810b289d7b469a97cb3cc0201f2c2d"
      }
     },
     "c73aee01ec114fb49729ee087e345e18": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "cc810b289d7b469a97cb3cc0201f2c2d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d0a994b47661469e970a7bb53c870bd7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "d39a2be7135c4577a46d2f2883601e62": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "d7498c633b3f4da8994f8c6dc169ae1c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d937e516b2e14876b70b25a8c7c7b58c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f1bfd97638fd4abaa65680b3de92caaf",
       "max": 157.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a9c0a1baed9c416b8b271f4049f98320",
       "value": 157.0
      }
     },
     "de8cec17333c42e58028e1cbb5c76bc6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e42ddd7483364de498edaf16ed9de6b3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ab2c55d204d04993969f75420aa9a538",
       "max": 32.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d0a994b47661469e970a7bb53c870bd7",
       "value": 32.0
      }
     },
     "e5290c56af2d4f479b04800566e68e12": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e6f492e2a23f4643b84f18392177ec2c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e8dcfe73c4a249cf914c366f6e62747c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_54ae53b5871541898726ca9d36c96187",
        "IPY_MODEL_e42ddd7483364de498edaf16ed9de6b3",
        "IPY_MODEL_5af164b9ef114822b7abb41a0b54d004"
       ],
       "layout": "IPY_MODEL_8b01ea5b4e344128b1af4d95e8f1d47f"
      }
     },
     "eeba02b863514920af94e2f0f1f7d1d8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "efd00f044dfa40c7a9c25662e0829a17": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f1bfd97638fd4abaa65680b3de92caaf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f69dedf64ab34659a7cc58b6ecbf7373": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_207f5b1d97654c02aebd94f0b6bcea53",
       "placeholder": "​",
       "style": "IPY_MODEL_ba00a20aabb44d9d943d6a58c952b4c1",
       "value": "Downloading data files: 100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
